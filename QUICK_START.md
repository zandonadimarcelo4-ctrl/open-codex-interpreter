# üöÄ Quick Start - Open Codex Interpreter

## Setup R√°pido (Windows)

### 1Ô∏è‚É£ Executar Setup Autom√°tico
```batch
setup_windows.bat
```

Este script ir√°:
- ‚úÖ Verificar Python
- ‚úÖ Criar ambiente virtual (.venv)
- ‚úÖ Instalar todas as depend√™ncias
- ‚úÖ Criar arquivo `.env` com configura√ß√µes padr√£o
- ‚úÖ Criar diret√≥rios necess√°rios (data/, data/uploads/, data/cache/)

### 2Ô∏è‚É£ Iniciar Servidor
```batch
start_windows.bat
```

Ou manualmente:
```batch
.venv\Scripts\activate
python -m uvicorn open_webui.main:app --host 0.0.0.0 --port 8080 --reload
```

### 3Ô∏è‚É£ Acessar Interface Web
Abra no navegador:
```
http://localhost:8080
```

## üìã Setup Manual (Passo a Passo)

### Pr√©-requisitos
- ‚úÖ Python 3.10 ou superior
- ‚úÖ pip (vem com Python)

### Passo 1: Criar Ambiente Virtual
```batch
python -m venv .venv
```

### Passo 2: Ativar Ambiente Virtual
```batch
.venv\Scripts\activate
```

### Passo 3: Instalar Depend√™ncias
```batch
pip install --upgrade pip
pip install -r requirements.txt
```

### Passo 4: Configurar Ambiente
```batch
copy env.example .env
```

Edite o `.env` se necess√°rio (valores padr√£o funcionam).

### Passo 5: Criar Diret√≥rios
```batch
mkdir data
mkdir data\uploads
mkdir data\cache
```

### Passo 6: Iniciar Servidor
```batch
start_windows.bat
```

## üéØ Configura√ß√£o M√≠nima

O projeto funciona com configura√ß√£o m√≠nima:

1. **Banco de Dados**: SQLite (autom√°tico, n√£o precisa configurar)
2. **Porta**: 8080 (padr√£o)
3. **Host**: 0.0.0.0 (aceita conex√µes de qualquer IP)

**Vari√°veis opcionais:**
- `OLLAMA_BASE_URL` - Se usar Ollama (padr√£o: http://localhost:11434)
- `OPENAI_API_KEY` - Se usar OpenAI (opcional)

## üß™ Testar Instala√ß√£o

### 1. Verificar Python
```batch
python --version
```
Deve mostrar Python 3.10 ou superior.

### 2. Verificar Depend√™ncias
```batch
python -c "import fastapi; print('FastAPI OK')"
python -c "import uvicorn; print('Uvicorn OK')"
```

### 3. Iniciar e Testar
```batch
start_windows.bat
```

Acesse: http://localhost:8080

## üîß Configura√ß√£o Opcional

### Usar Ollama (Modelos Locais)

1. **Instalar Ollama:**
   - Windows: https://ollama.ai/download
   - Baixe e instale

2. **Iniciar Ollama:**
   ```batch
   ollama serve
   ```

3. **Baixar um modelo:**
   ```batch
   ollama pull llama2
   ```

4. **Configurar no .env:**
   ```env
   OLLAMA_BASE_URL=http://localhost:11434
   ENABLE_OLLAMA_API=True
   ```

### Usar OpenAI

1. **Obter API Key:**
   - Acesse: https://platform.openai.com/api-keys
   - Crie uma chave

2. **Configurar no .env:**
   ```env
   OPENAI_API_KEY=sk-...
   ENABLE_OPENAI_API=True
   ```

## üêõ Problemas Comuns

### Erro: "ModuleNotFoundError"
**Solu√ß√£o:** Ative o ambiente virtual:
```batch
.venv\Scripts\activate
```

### Erro: "Port already in use"
**Solu√ß√£o:** Altere a porta no `.env`:
```env
PORT=8081
```

### Erro: "Database connection failed"
**Solu√ß√£o:** Certifique-se de que o diret√≥rio `data/` existe:
```batch
mkdir data
```

### Erro: "Ollama connection failed"
**Solu√ß√£o:** 
- Verifique se Ollama est√° rodando: `ollama serve`
- Ou desabilite: `ENABLE_OLLAMA_API=False` no `.env`

## üìù Pr√≥ximos Passos

1. ‚úÖ **Acessar Interface**: http://localhost:8080
2. ‚úÖ **Criar Usu√°rio**: A interface pedir√° para criar um usu√°rio admin
3. ‚úÖ **Configurar Modelo**: Adicione Ollama ou OpenAI
4. ‚úÖ **Testar Chat**: Comece a usar!

## üí° Dicas

- **Desenvolvimento**: Use `--reload` para auto-reload:
  ```batch
  uvicorn open_webui.main:app --reload
  ```

- **Produ√ß√£o**: Use m√∫ltiplos workers:
  ```env
  UVICORN_WORKERS=4
  ```

- **Logs**: Configure `GLOBAL_LOG_LEVEL=DEBUG` no `.env` para mais detalhes

---

**Pronto!** Agora voc√™ pode testar a interface web. üéâ

Para mais detalhes, veja `SETUP_GUIDE.md`.

