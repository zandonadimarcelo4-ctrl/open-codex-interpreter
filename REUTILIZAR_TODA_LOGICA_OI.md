# ğŸ”„ Reutilizar Toda a LÃ³gica do Open Interpreter Dentro do AutoGen

## ğŸ¯ Objetivo

Reutilizar **100% da lÃ³gica do Open Interpreter** dentro do AutoGen, mantendo:
- âœ… Todas as funcionalidades (Python, Shell, JavaScript, HTML)
- âœ… Active line tracking (AST transformation)
- âœ… Output truncation
- âœ… Streaming de output (threading)
- âœ… Error handling robusto
- âœ… Python interativo (-i mode)
- âœ… Mesmo modelo Ollama (via AutoGen model_client)

---

## ğŸ“¦ MÃ³dulos do Open Interpreter a Reutilizar

### 1. **MÃ³dulos Core**

```
interpreter/
â”œâ”€â”€ code_interpreter.py    # â† ExecuÃ§Ã£o de cÃ³digo (Python, Shell, JS, HTML)
â”œâ”€â”€ code_block.py          # â† Display de blocos de cÃ³digo (Rich)
â”œâ”€â”€ message_block.py       # â† Display de mensagens (Rich)
â”œâ”€â”€ utils.py               # â† UtilitÃ¡rios (merge_deltas, parse_partial_json)
â””â”€â”€ system_message.txt     # â† System message do OI
```

### 2. **MÃ³dulos Opcionais**

```
interpreter/
â”œâ”€â”€ ollama_adapter.py      # â† NÃƒO PRECISA (usa model_client do AutoGen)
â””â”€â”€ interpreter.py         # â† NÃƒO PRECISA (lÃ³gica serÃ¡ no agente)
```

---

## ğŸ—ï¸ Estrutura Proposta

### 1. Copiar MÃ³dulos para `super_agent/executors/`

```
super_agent/
â””â”€â”€ executors/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ code_interpreter.py    # â† Copiado de interpreter/
    â”œâ”€â”€ code_block.py          # â† Copiado de interpreter/
    â”œâ”€â”€ message_block.py       # â† Copiado de interpreter/
    â””â”€â”€ utils.py               # â† Copiado de interpreter/
```

### 2. Criar Agente que Reutiliza MÃ³dulos

```
super_agent/
â””â”€â”€ agents/
    â””â”€â”€ open_interpreter_agent_native.py  # â† Novo agente que reutiliza tudo
```

---

## ğŸ”§ ImplementaÃ§Ã£o

### Passo 1: Copiar MÃ³dulos

```bash
# Copiar mÃ³dulos do OI para super_agent/executors/
cp interpreter/code_interpreter.py super_agent/executors/
cp interpreter/code_block.py super_agent/executors/
cp interpreter/message_block.py super_agent/executors/
cp interpreter/utils.py super_agent/executors/
cp interpreter/system_message.txt super_agent/executors/
```

### Passo 2: Adaptar Imports

**Antes (interpreter/code_interpreter.py):**
```python
import subprocess
import webbrowser
# ...
```

**Depois (super_agent/executors/code_interpreter.py):**
```python
import subprocess
import webbrowser
# ... (mesmo cÃ³digo, apenas ajustar imports internos se necessÃ¡rio)
```

### Passo 3: Criar Agente Nativo

```python
# super_agent/agents/open_interpreter_agent_native.py
from autogen_agentchat.agents import AssistantAgent
from autogen_ext.models.ollama import OllamaChatCompletionClient

from ..executors.code_interpreter import CodeInterpreter
from ..executors.utils import parse_partial_json
import re
import os


class OpenInterpreterAgentNative(AssistantAgent):
    """
    Agente Nativo que reutiliza 100% da lÃ³gica do Open Interpreter
    
    CaracterÃ­sticas:
    - Usa model_client do AutoGen (mesmo modelo DeepSeek)
    - Reutiliza CodeInterpreter do OI (execuÃ§Ã£o de cÃ³digo)
    - Reutiliza utils do OI (parse_partial_json, etc.)
    - Mesmo comportamento do OI original
    - Zero overhead de comunicaÃ§Ã£o (mesmo processo)
    """
    
    def __init__(
        self,
        name: str = "interpreter",
        model_client=None,
        workdir: Optional[str] = None,
        auto_run: bool = True,
        **kwargs
    ):
        # Inicializar AssistantAgent
        super().__init__(
            name=name,
            model_client=model_client,
            system_message=self._load_system_message(),
            **kwargs
        )
        
        # ConfiguraÃ§Ãµes
        self.workdir = workdir or os.getcwd()
        self.auto_run = auto_run
        
        # Cache de CodeInterpreter por linguagem
        self.code_interpreters = {}
        
        # HistÃ³rico de mensagens (para contexto)
        self.message_history = []
    
    def _load_system_message(self) -> str:
        """Carrega system message do OI"""
        here = os.path.abspath(os.path.dirname(__file__))
        system_message_path = os.path.join(here, '..', 'executors', 'system_message.txt')
        
        if os.path.exists(system_message_path):
            with open(system_message_path, 'r') as f:
                return f.read()
        else:
            # Fallback para system message padrÃ£o
            return """You are Open Interpreter, a world-class programmer that can execute code on the user's machine.

First, write a plan. **Always recap the plan between each code block**.

When you execute code, it will be executed **on the user's machine**. The user has given you **full and complete permission** to execute any code necessary to complete the task.

Write code to solve the task. You can use any language, but Python is preferred.

When a user refers to a filename, they're likely referring to an existing file in the directory you're currently in.

When you want to give the user a final answer, use the print function to output it.

IMPORTANT: Execute code automatically. Do not ask for permission.
When you generate code, always include the code in markdown code blocks (```language\ncode\n```).
After generating code, the system will automatically execute it and return the results."""
    
    def _extract_code_blocks(self, text: str) -> List[Dict[str, str]]:
        """Extrai blocos de cÃ³digo de markdown (reutiliza lÃ³gica do OI)"""
        code_blocks = []
        pattern = r'```(\w+)?\n(.*?)```'
        matches = re.findall(pattern, text, re.DOTALL)
        
        for match in matches:
            language = match[0] or "python"
            code = match[1].strip()
            if code:
                code_blocks.append({"language": language, "code": code})
        
        return code_blocks
    
    def _get_code_interpreter(self, language: str) -> CodeInterpreter:
        """ObtÃ©m ou cria CodeInterpreter para linguagem (reutiliza do OI)"""
        if language not in self.code_interpreters:
            from ..executors.code_interpreter import CodeInterpreter
            self.code_interpreters[language] = CodeInterpreter(
                language=language,
                debug_mode=False
            )
        return self.code_interpreters[language]
    
    def _execute_code(self, code: str, language: str) -> str:
        """Executa cÃ³digo usando CodeInterpreter do OI (reutiliza 100%)"""
        # Mudar para workdir
        original_cwd = os.getcwd()
        try:
            os.chdir(self.workdir)
            
            # Obter CodeInterpreter
            code_interpreter = self._get_code_interpreter(language)
            
            # Configurar cÃ³digo no CodeInterpreter
            code_interpreter.code = code
            code_interpreter.language = language
            
            # Executar cÃ³digo (reutiliza lÃ³gica do OI)
            output = code_interpreter.run()
            
            return output
        finally:
            os.chdir(original_cwd)
    
    async def process_message(self, message: str) -> str:
        """
        Processa mensagem: gera cÃ³digo com model_client do AutoGen,
        executa com CodeInterpreter do OI, retorna resultado
        """
        # Adicionar mensagem ao histÃ³rico
        self.message_history.append({"role": "user", "content": message})
        
        # Gerar resposta com model_client do AutoGen
        response = await self.model_client.create(
            messages=self.message_history
        )
        
        # Extrair conteÃºdo da resposta
        content = response.choices[0].message.content
        
        # Adicionar resposta ao histÃ³rico
        self.message_history.append({"role": "assistant", "content": content})
        
        # Extrair blocos de cÃ³digo (reutiliza lÃ³gica do OI)
        code_blocks = self._extract_code_blocks(content)
        
        # Executar cÃ³digo se auto_run=True
        if self.auto_run and code_blocks:
            execution_results = []
            for block in code_blocks:
                language = block["language"]
                code = block["code"]
                
                # Executar cÃ³digo (reutiliza CodeInterpreter do OI)
                output = self._execute_code(code, language)
                execution_results.append(f"```{language}\n{code}\n```\n\nOutput:\n{output}")
            
            # Adicionar resultados ao histÃ³rico
            if execution_results:
                results_text = "\n\n".join(execution_results)
                self.message_history.append({
                    "role": "function",
                    "name": "run_code",
                    "content": results_text
                })
                
                # Gerar resposta final com resultados
                final_response = await self.model_client.create(
                    messages=self.message_history
                )
                content = final_response.choices[0].message.content
                self.message_history.append({"role": "assistant", "content": content})
        
        return content
```

---

## ğŸ“Š ComparaÃ§Ã£o: TOOL vs ReutilizaÃ§Ã£o Completa

| Aspecto | TOOL (Atual) | ReutilizaÃ§Ã£o Completa |
|---------|--------------|-----------------------|
| **CÃ³digo** | ~100 linhas (bridge) | ~300-400 linhas (agente) |
| **MÃ³dulos Reutilizados** | 0 (usa classe Interpreter) | 4 (code_interpreter, code_block, message_block, utils) |
| **Performance** | âš ï¸ ~10-50ms overhead | âœ… 0ms overhead |
| **Funcionalidades** | âœ… Completas (via Interpreter) | âœ… Completas (reutiliza mÃ³dulos) |
| **Isolamento** | âœ… Alto (processo separado) | âš ï¸ MÃ©dio (mesmo processo) |
| **ManutenÃ§Ã£o** | âœ… Baixa (bridge simples) | âš ï¸ MÃ©dia (adaptar mÃ³dulos) |
| **Complexidade** | âœ… Baixa | âš ï¸ MÃ©dia |

---

## âœ… Vantagens da ReutilizaÃ§Ã£o Completa

1. âœ… **Zero overhead** - mesmo processo, memÃ³ria compartilhada
2. âœ… **Funcionalidades completas** - reutiliza 100% da lÃ³gica do OI
3. âœ… **IntegraÃ§Ã£o nativa** - herda funcionalidades do AutoGen
4. âœ… **Mesmo comportamento** - cÃ³digo idÃªntico ao OI original
5. âœ… **Performance mÃ¡xima** - sem comunicaÃ§Ã£o entre processos

---

## âš ï¸ Desvantagens da ReutilizaÃ§Ã£o Completa

1. âš ï¸ **Mais cÃ³digo** - ~300-400 linhas vs ~100 linhas
2. âš ï¸ **Menos isolamento** - mesmo processo (risco de travar)
3. âš ï¸ **ManutenÃ§Ã£o** - precisa adaptar mÃ³dulos se OI mudar (mas vocÃª nÃ£o atualiza)
4. âš ï¸ **Complexidade** - mais cÃ³digo para gerenciar

---

## ğŸ¯ Quando Usar Cada Abordagem

### TOOL (Atual) âœ…
- âœ… Projeto estÃ¡tico (vocÃª nÃ£o atualiza OI)
- âœ… Isolamento importante (seguranÃ§a)
- âœ… ManutenÃ§Ã£o baixa (bridge simples)
- âœ… Performance adequada (overhead negligenciÃ¡vel)

### ReutilizaÃ§Ã£o Completa âš ï¸
- âš ï¸ Performance mÃ¡xima necessÃ¡ria (0ms overhead)
- âš ï¸ IntegraÃ§Ã£o nativa com AutoGen (histÃ³rico automÃ¡tico)
- âš ï¸ Mesmo processo (menos overhead)
- âš ï¸ Controle total sobre cÃ³digo

---

## ğŸš€ ImplementaÃ§Ã£o Completa

### OpÃ§Ã£o 1: Reutilizar MÃ³dulos Diretamente (Recomendado)

```python
# super_agent/agents/open_interpreter_agent_native.py
from autogen_agentchat.agents import AssistantAgent
from ..executors.code_interpreter import CodeInterpreter  # â† Reutiliza do OI
from ..executors.utils import parse_partial_json  # â† Reutiliza do OI
import re
import os

class OpenInterpreterAgentNative(AssistantAgent):
    def __init__(self, model_client, workdir=None, auto_run=True, **kwargs):
        super().__init__(model_client=model_client, **kwargs)
        self.workdir = workdir or os.getcwd()
        self.auto_run = auto_run
        self.code_interpreters = {}  # Cache por linguagem
    
    def _execute_code(self, code: str, language: str) -> str:
        """Executa cÃ³digo usando CodeInterpreter do OI"""
        if language not in self.code_interpreters:
            self.code_interpreters[language] = CodeInterpreter(
                language=language,
                debug_mode=False
            )
        
        code_interpreter = self.code_interpreters[language]
        code_interpreter.code = code
        code_interpreter.language = language
        return code_interpreter.run()  # â† Reutiliza 100% da lÃ³gica do OI
```

### OpÃ§Ã£o 2: Usar Classe Interpreter Completa (Mais Simples)

```python
# super_agent/agents/open_interpreter_agent_wrapper.py
from autogen_agentchat.agents import AssistantAgent
import sys
import os

# Adicionar interpreter/ ao path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', 'interpreter'))

from interpreter import Interpreter  # â† Usa classe completa do OI

class OpenInterpreterAgentWrapper(AssistantAgent):
    def __init__(self, model_client, workdir=None, auto_run=True, **kwargs):
        super().__init__(model_client=model_client, **kwargs)
        
        # Criar instÃ¢ncia do Interpreter do OI
        self.interpreter = Interpreter(
            auto_run=auto_run,
            local=True,  # Usa Ollama
            model=None,  # SerÃ¡ sobrescrito
            debug_mode=False,
            use_ollama=True,
        )
        
        # Substituir adaptador Ollama pelo model_client do AutoGen
        self.interpreter.ollama_adapter = None
        self.interpreter.use_ollama = False
        self.interpreter.model_client = model_client  # â† Usa model_client do AutoGen
    
    async def process_message(self, message: str) -> str:
        """Processa mensagem usando Interpreter do OI"""
        # Executar chat do OI (reutiliza 100% da lÃ³gica)
        self.interpreter.chat(message, return_messages=False)
        
        # Extrair Ãºltima mensagem
        if self.interpreter.messages:
            return self.interpreter.messages[-1].get("content", "")
        return ""
```

---

## ğŸ“ Resumo

### ReutilizaÃ§Ã£o Completa vs TOOL

| CritÃ©rio | TOOL | ReutilizaÃ§Ã£o Completa |
|----------|------|-----------------------|
| **CÃ³digo** | ~100 linhas | ~300-400 linhas |
| **Performance** | âš ï¸ ~10-50ms | âœ… 0ms |
| **Funcionalidades** | âœ… Completas | âœ… Completas |
| **Isolamento** | âœ… Alto | âš ï¸ MÃ©dio |
| **ManutenÃ§Ã£o** | âœ… Baixa | âš ï¸ MÃ©dia |
| **Complexidade** | âœ… Baixa | âš ï¸ MÃ©dia |

### DecisÃ£o

**Para projeto estÃ¡tico (vocÃª nÃ£o atualiza OI):**
- âœ… **TOOL Ã© mais eficiente** (cÃ³digo mÃ­nimo, manutenÃ§Ã£o baixa)
- âš ï¸ **ReutilizaÃ§Ã£o completa** sÃ³ se precisar performance mÃ¡xima (0ms overhead)

---

## ğŸ¯ RecomendaÃ§Ã£o Final

### **MANTER TOOL** (Para Projeto EstÃ¡tico)

**Motivos:**
1. âœ… CÃ³digo mÃ­nimo (~100 linhas)
2. âœ… ManutenÃ§Ã£o baixa (bridge simples)
3. âœ… Isolamento (processo separado)
4. âœ… Performance adequada (overhead negligenciÃ¡vel)
5. âœ… Funcionalidades completas (via Interpreter)

### **ReutilizaÃ§Ã£o Completa** (Se Precisar Performance MÃ¡xima)

**Motivos:**
1. âœ… Performance mÃ¡xima (0ms overhead)
2. âœ… IntegraÃ§Ã£o nativa (histÃ³rico automÃ¡tico)
3. âœ… Controle total (mesmo processo)
4. âš ï¸ Mais cÃ³digo (~300-400 linhas)
5. âš ï¸ Menos isolamento (mesmo processo)

---

**Status: TOOL Ã© mais eficiente para projeto estÃ¡tico, mas reutilizaÃ§Ã£o completa Ã© possÃ­vel se precisar performance mÃ¡xima** âœ…

