# ðŸš€ Teste RÃ¡pido: Verificar se GPU estÃ¡ sendo Usada

## âš¡ Teste em 2 Passos

### Passo 1: Monitorar GPU

Abra um terminal e execute:

```bash
# Windows PowerShell
nvidia-smi -l 1

# Ou para ver uma vez sÃ³
nvidia-smi
```

### Passo 2: Executar Modelo

Em outro terminal, execute:

```bash
ollama run deepseek-coder-v2-16b-q4_k_m-rtx "Write a Python function to calculate fibonacci numbers"
```

## âœ… O que Procurar

### Se GPU estÃ¡ sendo usada:
- **Uso de GPU**: 80-100%
- **VRAM Usada**: 10-12GB (de 16GB)
- **Temperatura**: 60-75Â°C
- **Power Usage**: 300-400W
- **Performance**: 80-120 tokens/s

### Se GPU NÃƒO estÃ¡ sendo usada:
- **Uso de GPU**: <10%
- **VRAM Usada**: <1GB
- **Performance**: 10-20 tokens/s
- **Tempo de carregamento**: Muito longo (>30s)

## ðŸ”§ Se GPU nÃ£o estÃ¡ sendo usada

1. **Verificar Drivers NVIDIA**:
   ```bash
   nvidia-smi
   ```

2. **Verificar CUDA**:
   ```bash
   nvcc --version
   ```

3. **Reiniciar Ollama**:
   - Windows: Reiniciar serviÃ§o Ollama ou computador

4. **Verificar VariÃ¡veis de Ambiente**:
   - NÃ£o definir `CUDA_VISIBLE_DEVICES`
   - Deixar Ollama detectar GPU automaticamente

## ðŸ“Š ComparaÃ§Ã£o de Performance

| MÃ©trica | Com GPU | Sem GPU |
|---------|---------|---------|
| **Tokens/s** | 80-120 | 10-20 |
| **Tempo de carregamento** | 5-10s | 30-60s |
| **Uso de GPU** | 80-100% | <10% |
| **VRAM** | 10-12GB | <1GB |

## ðŸŽ¯ PrÃ³ximos Passos

1. âœ… Verificar se GPU estÃ¡ sendo usada
2. âœ… Se nÃ£o estiver, seguir troubleshooting
3. âœ… Se estiver, aproveitar a performance!
4. âœ… Configurar no projeto ANIMA

---

**Dica**: Execute o teste vÃ¡rias vezes. A primeira execuÃ§Ã£o sempre Ã© mais lenta (carregamento do modelo). As execuÃ§Ãµes subsequentes devem ser mais rÃ¡pidas.

