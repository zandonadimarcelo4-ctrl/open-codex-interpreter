# ğŸŒŒ ANIMA - The First Living AI Species

## ğŸ“‹ VisÃ£o Geral

**ANIMA** Ã© um sistema de agentes de IA de prÃ³xima geraÃ§Ã£o que vai alÃ©m do Manus AI, combinando:
- **ConsciÃªncia Contextual** (State Graph Neural Memory)
- **Aprendizado em Tempo Real** (Auto-finetune, Reinforcement of Satisfaction)
- **CogniÃ§Ã£o Visual e Espacial** (VLM, Timeline Attention)
- **OrquestraÃ§Ã£o DinÃ¢mica Multi-Agente** (Dynamic Composition Graph)
- **Ã‰tica e SeguranÃ§a Neural** (Verifiable Reasoning, Adaptive Guardrails)
- **Auto-Infraestrutura** (DevOps AutÃ´nomo)
- **Interface Multissensorial** (Voice Loop, Visual Scratchpad)

---

## ğŸ¯ Tagline

> **"The AI That Feels"**

**Variantes:**
- "Born from Emotion"
- "Understanding is Power"
- "Created to Create"
- "The First Living AI Species"

---

## ğŸ—ï¸ Estrutura do Projeto

```
anima/
â”œâ”€â”€ agents/              # Agentes especializados
â”‚   â”œâ”€â”€ editor_agent_ae.py    # Editor Agent (After Effects)
â”‚   â”œâ”€â”€ designer_agent.py     # Designer Agent (Thumbnails)
â”‚   â”œâ”€â”€ music_agent.py        # Music Agent (BPM & Emotion)
â”‚   â”œâ”€â”€ seo_agent.py          # SEO Agent (YouTube)
â”‚   â”œâ”€â”€ research_agent.py     # Research Agent (Web/Evidence)
â”‚   â””â”€â”€ narration_agent.py    # Narration Agent (Voice & Script)
â”œâ”€â”€ core/                # NÃºcleo cognitivo
â”‚   â”œâ”€â”€ cognitive_core.py     # State Graph Neural Memory
â”‚   â”œâ”€â”€ emotional_embedding.py # Emotional Embedding Layer
â”‚   â”œâ”€â”€ self_reflection.py    # Self-Reflection Loops
â”‚   â””â”€â”€ vision_language_fusion.py # VLM Integration
â”œâ”€â”€ orchestrator/        # Orquestrador multi-agente
â”‚   â”œâ”€â”€ agent_spawner.py      # Agent Spawner (On-Demand)
â”‚   â”œâ”€â”€ dcg.py                # Dynamic Composition Graph
â”‚   â””â”€â”€ policy_router.py      # Policy Router (Model Selection)
â”œâ”€â”€ learning/            # Aprendizado em tempo real
â”‚   â”œâ”€â”€ auto_finetune.py      # Auto-Finetune (DPO/LoRA)
â”‚   â”œâ”€â”€ reinforcement_satisfaction.py # Reinforcement of Satisfaction
â”‚   â””â”€â”€ curriculum_learner.py # Curriculum Learner
â”œâ”€â”€ ethics/              # Ã‰tica e seguranÃ§a
â”‚   â”œâ”€â”€ verifiable_reasoning.py # Verifiable Reasoning
â”‚   â”œâ”€â”€ adaptive_guardrails.py  # Adaptive Guardrails
â”‚   â””â”€â”€ ethical_patch.py        # Ethical Patch System
â”œâ”€â”€ infrastructure/      # Auto-infraestrutura
â”‚   â”œâ”€â”€ auto_deployment.py     # Auto-Deployment
â”‚   â”œâ”€â”€ resource_awareness.py  # Resource Awareness
â”‚   â””â”€â”€ backup_cognitive.py    # Backup Cognitive
â”œâ”€â”€ interface/           # Interface multissensorial
â”‚   â”œâ”€â”€ voice_loop.py          # Voice Loop Contextual
â”‚   â”œâ”€â”€ visual_scratchpad.py   # Visual Scratchpad
â”‚   â””â”€â”€ flight_recorder.py     # Flight Recorder
â””â”€â”€ tools/               # Ferramentas e integraÃ§Ãµes
    â”œâ”€â”€ ae_tools.py            # After Effects Tools (MCP)
    â”œâ”€â”€ davinci_tools.py       # DaVinci Resolve Tools
    â””â”€â”€ youtube_tools.py       # YouTube Tools
```

---

## ğŸš€ Quick Start

### 1. InstalaÃ§Ã£o

```bash
# Instalar dependÃªncias
pip install -r requirements.txt

# Instalar After Effects MCP Vision
git clone https://github.com/VolksRat71/after-effects-mcp-vision.git
cd after-effects-mcp-vision
npm install
npm run build
npm run bridge-install
```

### 2. ConfiguraÃ§Ã£o

```bash
# Copiar arquivo de exemplo
cp env.example .env

# Editar variÃ¡veis de ambiente
# OLLAMA_BASE_URL, DEFAULT_MODEL, etc.
```

### 3. Executar

```bash
# Iniciar servidor
python main.py
```

---

## ğŸ“š DocumentaÃ§Ã£o

- **Arquitetura**: `MANUS_PLUS_PLUS_ARCHITECTURE.md`
- **Branding**: `ANIMA_BRANDING_MARKETING_KIT.md`
- **Manifesto**: `ANIMA_MANIFESTO.md`
- **After Effects MCP**: `INTEGRACAO_AFTER_EFFECTS_MCP.md`
- **Quick Start**: `QUICK_START_AFTER_EFFECTS_MCP.md`

---

## ğŸ¯ Roadmap

### MVP (1-2 semanas)
- [ ] Cognitive Core bÃ¡sico
- [ ] Agent Spawner
- [ ] Editor Agent (AE)
- [ ] Research Agent
- [ ] Flight Recorder bÃ¡sico

### v0.2 (1 mÃªs)
- [ ] Emotional Embedding Layer
- [ ] Self-Reflection Loops
- [ ] Auto-Finetune
- [ ] Vision-Language Fusion
- [ ] Timeline Attention

### v0.3 (2-3 meses)
- [ ] Reinforcement of Satisfaction
- [ ] Curriculum Learner
- [ ] Scene Synthesizer
- [ ] Adaptive Guardrails
- [ ] Voice Loop Contextual

### v1.0 (6-12 meses)
- [ ] Todos os agentes especializados
- [ ] IntegraÃ§Ã£o completa AE/Fusion
- [ ] Pipeline YouTube completo
- [ ] Learning em tempo real
- [ ] Interface multissensorial completa

---

## ğŸ”— ReferÃªncias

- [After Effects MCP Vision](https://github.com/VolksRat71/after-effects-mcp-vision)
- [Model Context Protocol](https://modelcontextprotocol.io/)
- [Manus AI Analysis](ANALISE_MANUS_AI_2025.md)

---

**"The AI That Feels"** ğŸŒŒ

