# ğŸ™ï¸ ComparaÃ§Ã£o de Modelos de TranscriÃ§Ã£o de Ãudio (STT)

Este documento compara os diferentes modelos de IA disponÃ­veis para transcriÃ§Ã£o de Ã¡udio no projeto.

## ğŸ“Š Modelos DisponÃ­veis

### 1. **Faster-Whisper** (PadrÃ£o) âš¡
- **Velocidade**: â­â­â­â­ (RÃ¡pido)
- **PrecisÃ£o**: â­â­â­â­ (Muito boa)
- **Idiomas**: 99+ idiomas
- **Requer GPU**: NÃ£o (funciona bem em CPU)
- **Custo**: Gratuito (open-source)
- **Recomendado para**: Uso geral, produÃ§Ã£o

**Modelos disponÃ­veis:**
- `tiny` - Mais rÃ¡pido, menor precisÃ£o (~39MB)
- `base` - Balanceado (padrÃ£o) (~74MB) â­
- `small` - Melhor precisÃ£o (~244MB)
- `medium` - Alta precisÃ£o (~769MB)
- `large` - MÃ¡xima precisÃ£o (~1550MB)

**ConfiguraÃ§Ã£o:**
```bash
# VariÃ¡veis de ambiente
STT_MODEL=faster-whisper
STT_MODEL_SIZE=base  # tiny, base, small, medium, large
STT_DEVICE=cpu  # cpu, cuda
STT_COMPUTE_TYPE=int8  # int8, float16, float32
```

---

### 2. **Distil-Whisper** ğŸš€
- **Velocidade**: â­â­â­â­â­ (Muito rÃ¡pido)
- **PrecisÃ£o**: â­â­â­ (Boa, mas menor que Faster-Whisper)
- **Idiomas**: InglÃªs (distil-medium.en) ou Multilingual (distil-large-v3)
- **Requer GPU**: Opcional (mais rÃ¡pido com GPU)
- **Custo**: Gratuito (open-source)
- **Recomendado para**: InglÃªs, tempo real, baixa latÃªncia

**Modelos disponÃ­veis:**
- `distil-whisper/distil-medium.en` - InglÃªs apenas
- `distil-whisper/distil-large-v3` - Multilingual

**ConfiguraÃ§Ã£o:**
```bash
STT_MODEL=distil-whisper
STT_DEVICE=cpu  # cpu, cuda, mps (Mac)
```

**InstalaÃ§Ã£o:**
```bash
pip install transformers torch pydub
```

---

### 3. **OpenAI Whisper API** ğŸ¯
- **Velocidade**: â­â­â­ (Moderado, depende da conexÃ£o)
- **PrecisÃ£o**: â­â­â­â­â­ (Excelente)
- **Idiomas**: 99+ idiomas
- **Requer GPU**: NÃ£o (processado na nuvem)
- **Custo**: $0.006 por minuto (~$0.36/hora)
- **Recomendado para**: Alta precisÃ£o, quando nÃ£o hÃ¡ recursos locais

**ConfiguraÃ§Ã£o:**
```bash
STT_MODEL=openai-api
OPENAI_API_KEY=sk-...
```

**InstalaÃ§Ã£o:**
```bash
pip install openai
```

---

## ğŸ“ˆ ComparaÃ§Ã£o Detalhada

| CaracterÃ­stica | Faster-Whisper | Distil-Whisper | OpenAI API |
|---------------|----------------|----------------|------------|
| **Velocidade** | RÃ¡pido | Muito RÃ¡pido | Moderado |
| **PrecisÃ£o** | Muito Boa | Boa | Excelente |
| **Idiomas** | 99+ | InglÃªs/Multilingual | 99+ |
| **Custo** | Gratuito | Gratuito | $0.006/min |
| **Requer Internet** | NÃ£o | NÃ£o | Sim |
| **Requer GPU** | NÃ£o | Opcional | NÃ£o |
| **Tamanho do Modelo** | 39MB-1.5GB | ~1GB | N/A |
| **LatÃªncia** | Baixa | Muito Baixa | MÃ©dia |
| **Privacidade** | 100% Local | 100% Local | Na nuvem |

---

## ğŸ¯ RecomendaÃ§Ãµes por Caso de Uso

### âœ… **Uso Geral (Recomendado)**
```bash
STT_MODEL=faster-whisper
STT_MODEL_SIZE=base
```
- Balance perfeito entre velocidade e precisÃ£o
- Funciona bem em CPU
- Suporta mÃºltiplos idiomas

### âš¡ **MÃ¡xima Velocidade (InglÃªs)**
```bash
STT_MODEL=distil-whisper
```
- Ideal para tempo real
- Baixa latÃªncia
- Principalmente para inglÃªs

### ğŸ¯ **MÃ¡xima PrecisÃ£o**
```bash
STT_MODEL=faster-whisper
STT_MODEL_SIZE=large
```
ou
```bash
STT_MODEL=openai-api
OPENAI_API_KEY=sk-...
```
- Melhor qualidade de transcriÃ§Ã£o
- Ideal para conteÃºdo importante
- Maior custo (OpenAI) ou recursos (Large)

### ğŸ’° **Baixo Custo / Sem Internet**
```bash
STT_MODEL=faster-whisper
STT_MODEL_SIZE=tiny
```
- Modelo menor e mais rÃ¡pido
- Funciona offline
- Menor precisÃ£o

---

## ğŸ”§ ConfiguraÃ§Ã£o

### 1. **VariÃ¡veis de Ambiente**
Crie um arquivo `.env` ou configure as variÃ¡veis:

```bash
# Modelo a usar
STT_MODEL=faster-whisper  # faster-whisper, distil-whisper, openai-api

# ConfiguraÃ§Ãµes do Faster-Whisper
STT_MODEL_SIZE=base  # tiny, base, small, medium, large
STT_DEVICE=cpu  # cpu, cuda
STT_COMPUTE_TYPE=int8  # int8, float16, float32

# OpenAI API (se usar openai-api)
OPENAI_API_KEY=sk-...
```

### 2. **Instalar DependÃªncias**

**Faster-Whisper (padrÃ£o):**
```bash
pip install faster-whisper pydub
```

**Distil-Whisper:**
```bash
pip install transformers torch pydub
```

**OpenAI API:**
```bash
pip install openai
```

### 3. **Usar no CÃ³digo**

O cÃ³digo automaticamente detecta a configuraÃ§Ã£o e usa o modelo apropriado.

---

## ğŸš€ Melhorias Futuras

- [ ] Suporte para Whisper Large v3
- [ ] Suporte para modelos locais multilÃ­ngues melhorados
- [ ] Cache de transcriÃ§Ãµes
- [ ] Suporte para streaming (tempo real)
- [ ] DetecÃ§Ã£o automÃ¡tica de idioma melhorada
- [ ] Suporte para mÃºltiplos falantes

---

## ğŸ“š ReferÃªncias

- [Faster-Whisper](https://github.com/guillaumekln/faster-whisper)
- [Distil-Whisper](https://huggingface.co/distil-whisper)
- [OpenAI Whisper API](https://platform.openai.com/docs/guides/speech-to-text)
- [Whisper (OpenAI)](https://github.com/openai/whisper)

