/**
 * Hook para Voz Jarvis (TTS) e Speech-to-Text (STT)
 */
import { useState, useRef, useCallback, useEffect } from 'react';

export interface UseVoiceOptions {
  ttsEnabled?: boolean;
  sttEnabled?: boolean;
  onTextReceived?: (text: string) => void;
  onAudioReady?: (audioUrl: string) => void;
}

export function useVoice(options: UseVoiceOptions = {}) {
  const {
    ttsEnabled = true,
    sttEnabled = true,
    onTextReceived,
    onAudioReady,
  } = options;

  const [isRecording, setIsRecording] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const audioContextRef = useRef<AudioContext | null>(null);
  const audioElementRef = useRef<HTMLAudioElement | null>(null);
  const isStartingRef = useRef<boolean>(false); // Flag para evitar m√∫ltiplas chamadas simult√¢neas

  // Inicializar √°udio element
  useEffect(() => {
    audioElementRef.current = new Audio();
    audioElementRef.current.onended = () => setIsSpeaking(false);
    audioElementRef.current.onerror = () => {
      // S√≥ logar erro se for um erro real
      if (audioElementRef.current?.error) {
        const errorCode = audioElementRef.current.error.code;
        // Ignorar erros comuns que n√£o s√£o cr√≠ticos
        // MEDIA_ERR_ABORTED = 1 (usu√°rio cancelou)
        if (errorCode !== 1) {
          console.warn('[TTS] Erro no elemento de √°udio (c√≥digo', errorCode, ')');
          setError('Erro ao reproduzir √°udio');
        }
      }
      setIsSpeaking(false);
    };

    return () => {
      if (audioElementRef.current) {
        audioElementRef.current.pause();
        audioElementRef.current = null;
      }
      if (audioContextRef.current) {
        audioContextRef.current.close();
        audioContextRef.current = null;
      }
    };
  }, []);

  /**
   * Reproduzir √°udio TTS (Text-to-Speech)
   */
  const speak = useCallback(async (text: string) => {
    if (!ttsEnabled || !text.trim()) {
      console.log('[TTS] TTS desabilitado ou texto vazio, ignorando');
      return;
    }

    // Parar qualquer √°udio anterior antes de iniciar um novo
    if (audioElementRef.current) {
      try {
        audioElementRef.current.pause();
        audioElementRef.current.currentTime = 0;
        audioElementRef.current.src = '';
      } catch (e) {
        // Ignorar erros ao parar √°udio anterior
      }
    }

    // Se j√° est√° falando, parar antes de iniciar novo
    if (isSpeaking) {
      console.log('[TTS] Parando √°udio anterior antes de iniciar novo');
      setIsSpeaking(false);
      // Aguardar um pouco para garantir que o √°udio anterior parou
      await new Promise(resolve => setTimeout(resolve, 100));
    }

    try {
      setIsSpeaking(true);
      setError(null);

      // Limpar texto removendo emojis e caracteres especiais antes de enviar
      // Remover TODOS os caracteres Unicode acima de 0x7F exceto acentos portugueses
      let cleanedText = text.split('').filter(char => {
        const code = char.charCodeAt(0);
        // Manter apenas ASCII b√°sico (0-127) e acentos portugueses (0x00C0-0x017F)
        return code <= 0x7F || (code >= 0x00C0 && code <= 0x017F);
      }).join('');
      
      // Remover markdown e caracteres especiais
      cleanedText = cleanedText.replace(/#{1,6}\s+/g, ''); // Headers
      cleanedText = cleanedText.replace(/\*\*/g, ''); // Bold
      cleanedText = cleanedText.replace(/\*/g, ''); // Italic
      cleanedText = cleanedText.replace(/__/g, ''); // Bold
      cleanedText = cleanedText.replace(/_/g, ''); // Italic
      cleanedText = cleanedText.replace(/`/g, ''); // Code
      cleanedText = cleanedText.replace(/\[([^\]]+)\]\([^\)]+\)/g, '$1'); // Links
      cleanedText = cleanedText.replace(/!\[([^\]]*)\]\([^\)]+\)/g, ''); // Images
      cleanedText = cleanedText.replace(/[^\x00-\x7F\u00C0-\u017F\s.,!?;:()\-]/g, ' '); // Remover caracteres especiais
      cleanedText = cleanedText.replace(/\s+/g, ' ').trim(); // Normalizar espa√ßos
      
      if (!cleanedText.trim()) {
        console.warn('‚ö†Ô∏è Texto vazio ap√≥s limpeza, n√£o enviando para TTS');
        setIsSpeaking(false);
        return;
      }

      // Usar APENAS API de TTS do backend (ElevenLabs/Piper)
      console.log('üéôÔ∏è Tentando usar API de TTS do backend (ElevenLabs/Piper)...');
      console.log(`üìù Texto original (${text.length} chars) -> Limpo (${cleanedText.length} chars)`);
      console.log(`üìù Texto limpo (primeiros 100 chars): ${cleanedText.substring(0, 100)}`);
      
      try {
        const apiUrl = '/api/tts';
        console.log(`[TTS] Enviando requisi√ß√£o para: ${apiUrl}`);
        console.log(`[TTS] Texto a ser enviado: ${cleanedText.substring(0, 200)}...`);
        
        const response = await fetch(apiUrl, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({ text: cleanedText }),
        });
        
        console.log(`[TTS] Resposta recebida: status=${response.status}, ok=${response.ok}, contentType=${response.headers.get('content-type')}`);

        if (response.ok) {
          const contentType = response.headers.get('content-type');
          console.log(`[TTS] Content-Type recebido: ${contentType}`);
          
          // Verificar se √© realmente √°udio
          if (!contentType || !contentType.startsWith('audio/')) {
            console.warn(`[TTS] ‚ö†Ô∏è Content-Type inesperado: ${contentType}, tentando processar como √°udio mesmo assim`);
          }
          
          const audioBlob = await response.blob();
          console.log(`[TTS] Blob recebido: tamanho=${audioBlob.size} bytes, type=${audioBlob.type}`);
          
          if (audioBlob.size === 0) {
            throw new Error('√Åudio recebido est√° vazio (0 bytes)');
          }
          
          const audioUrl = URL.createObjectURL(audioBlob);
          console.log(`[TTS] ‚úÖ √Åudio recebido do backend TTS (ElevenLabs/Piper), tamanho: ${audioBlob.size} bytes`);

          if (!audioElementRef.current) {
            console.error('[TTS] ‚ùå audioElementRef.current √© null');
            setIsSpeaking(false);
            URL.revokeObjectURL(audioUrl);
            throw new Error('Elemento de √°udio n√£o est√° dispon√≠vel');
          }

          // Parar e limpar elemento anterior se existir
          if (audioElementRef.current) {
            try {
              audioElementRef.current.pause();
              audioElementRef.current.currentTime = 0;
              audioElementRef.current.src = '';
              // Remover todos os event listeners
              audioElementRef.current.onended = null;
              audioElementRef.current.onerror = null;
              audioElementRef.current.onloadeddata = null;
              audioElementRef.current.onloadstart = null;
            } catch (e) {
              // Ignorar erros
            }
          }

          // Criar novo elemento de √°udio (n√£o clonar para evitar problemas)
          const newAudioElement = new Audio();
          audioElementRef.current = newAudioElement;
          
          // Flag para garantir que s√≥ reproduz uma vez
          let hasPlayed = false;
          
          newAudioElement.src = audioUrl;
          
          // Configurar event listeners
          newAudioElement.onended = () => {
            console.log('[TTS] ‚úÖ √Åudio reproduzido com sucesso');
            setIsSpeaking(false);
            hasPlayed = false;
            URL.revokeObjectURL(audioUrl);
          };
          
          newAudioElement.onerror = (error) => {
            // S√≥ logar erro se for um erro real (n√£o apenas um evento)
            if (newAudioElement.error) {
              const errorCode = newAudioElement.error.code;
              const errorMessage = newAudioElement.error.message;
              
              // Ignorar erros comuns que n√£o s√£o cr√≠ticos
              // MEDIA_ERR_ABORTED = 1 (usu√°rio cancelou)
              if (errorCode === 1) {
                // Usu√°rio cancelou - n√£o √© um erro real
                console.log('[TTS] Reprodu√ß√£o cancelada pelo usu√°rio');
                setIsSpeaking(false);
                hasPlayed = false;
                URL.revokeObjectURL(audioUrl);
                return;
              }
              
              // Logar apenas erros reais
              console.error(`[TTS] Erro no elemento de √°udio (c√≥digo ${errorCode}):`, errorMessage);
              setIsSpeaking(false);
              hasPlayed = false;
              const errorMsg = errorMessage || 'Erro ao reproduzir √°udio. Verifique se o formato de √°udio √© suportado.';
              setError(errorMsg);
            } else {
              // Se n√£o houver erro espec√≠fico, apenas limpar
              console.log('[TTS] Evento de erro sem detalhes - ignorando');
              setIsSpeaking(false);
              hasPlayed = false;
            }
            URL.revokeObjectURL(audioUrl);
          };
          
          newAudioElement.onloadeddata = async () => {
            // S√≥ reproduzir se ainda n√£o reproduziu
            if (!hasPlayed) {
              console.log('[TTS] √Åudio carregado, tentando reproduzir...');
              try {
                hasPlayed = true;
                await newAudioElement.play();
                console.log('[TTS] ‚úÖ √Åudio reproduzido com sucesso');
                onAudioReady?.(audioUrl);
              } catch (playError) {
                hasPlayed = false;
                console.error('‚ùå Erro ao reproduzir √°udio:', playError);
                setIsSpeaking(false);
                const errorMsg = playError instanceof Error 
                  ? `Erro ao reproduzir √°udio: ${playError.message}`
                  : 'Erro ao reproduzir √°udio. Verifique as permiss√µes do navegador.';
                setError(errorMsg);
                URL.revokeObjectURL(audioUrl);
              }
            }
          };
          
          newAudioElement.onloadstart = () => {
            console.log('[TTS] Iniciando carregamento do √°udio...');
          };
          
          // Se o √°udio j√° estiver carregado, reproduzir imediatamente (mas s√≥ uma vez)
          if (newAudioElement.readyState >= 2 && !hasPlayed) {
            console.log(`[TTS] √Åudio j√° carregado (readyState=${newAudioElement.readyState}), reproduzindo imediatamente...`);
            try {
              hasPlayed = true;
              await newAudioElement.play();
              console.log('[TTS] ‚úÖ √Åudio reproduzido com sucesso');
              onAudioReady?.(audioUrl);
            } catch (playError) {
              hasPlayed = false;
              console.error('‚ùå Erro ao reproduzir √°udio:', playError);
              setIsSpeaking(false);
              const errorMsg = playError instanceof Error 
                ? `Erro ao reproduzir √°udio: ${playError.message}`
                : 'Erro ao reproduzir √°udio. Verifique as permiss√µes do navegador.';
              setError(errorMsg);
              URL.revokeObjectURL(audioUrl);
            }
          } else {
            // Aguardar o √°udio carregar
            console.log(`[TTS] √Åudio ainda n√£o carregado (readyState=${newAudioElement.readyState}), aguardando...`);
          }
          
          return;
        } else {
          // Tentar ler como JSON primeiro, depois como texto
          let errorText = '';
          try {
            const errorJson = await response.json();
            errorText = errorJson.error || JSON.stringify(errorJson);
          } catch {
            // Se n√£o for JSON, ler como texto
            errorText = await response.text();
            // Se for HTML (p√°gina de erro), extrair mensagem √∫til
            if (errorText.includes('<!doctype') || errorText.includes('<html')) {
              errorText = `Erro ${response.status}: P√°gina de erro HTML retornada (rota n√£o encontrada?)`;
            }
          }
          console.error('‚ùå Erro na API de TTS:', response.status, errorText);
          setError(`Erro na API de TTS: ${response.status} - ${errorText.substring(0, 100)}`);
          throw new Error(`API de TTS retornou erro: ${response.status}`);
        }
      } catch (apiError) {
        console.error('‚ùå Erro ao chamar API de TTS:', apiError);
        setError('Erro ao chamar API de TTS. Verifique se o backend est√° rodando e se ElevenLabs est√° configurado.');
        throw apiError; // N√£o usar fallback - for√ßar uso do backend
      }

      // REMOVIDO: Fallback para Web Speech API (soa como Google Tradutor)
      // Usar APENAS ElevenLabs/Piper do backend
      throw new Error('TTS n√£o dispon√≠vel: API do backend n√£o respondeu corretamente');
      
      // C√ìDIGO COMENTADO - N√£o usar Web Speech API
      /*
      // Fallback para Web Speech API
          if ('speechSynthesis' in window) {
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'pt-BR';  // FOR√áAR portugu√™s brasileiro
            utterance.rate = 0.92;  // Ligeiramente mais lento para soar mais natural
            utterance.pitch = 1.0;
            utterance.volume = 1.0;
            
            // Tentar usar voz neural mais natural se dispon√≠vel
            const voices = window.speechSynthesis.getVoices();
            // Priorizar vozes neurais brasileiras
            const ptBRVoice = voices.find((v: SpeechSynthesisVoice) => 
              v.lang === 'pt-BR' && (v.name.includes('Neural') || v.name.includes('Google') || v.name.includes('Brazil'))
            ) || voices.find((v: SpeechSynthesisVoice) => 
              v.lang.startsWith('pt-BR')
            ) || voices.find((v: SpeechSynthesisVoice) => 
              v.lang.startsWith('pt')
            );
            if (ptBRVoice) {
              utterance.voice = ptBRVoice;
              utterance.lang = ptBRVoice.lang;  // Usar idioma da voz selecionada
            }
        
        utterance.onend = () => setIsSpeaking(false);
        utterance.onerror = (err) => {
          console.error('Erro na Web Speech API:', err);
          setError('Erro ao reproduzir √°udio com Web Speech API');
          setIsSpeaking(false);
        };
        
        window.speechSynthesis.speak(utterance);
      } else {
        throw new Error('TTS n√£o dispon√≠vel: API n√£o encontrada e Web Speech API n√£o suportada');
      }
      */
    } catch (err) {
      console.error('Erro ao falar:', err);
      setError(err instanceof Error ? err.message : 'Erro ao reproduzir √°udio');
      setIsSpeaking(false);
    }
  }, [ttsEnabled, onAudioReady]);

  /**
   * Parar de falar
   */
  const stopSpeaking = useCallback(() => {
    if (audioElementRef.current) {
      audioElementRef.current.pause();
      audioElementRef.current.currentTime = 0;
    }
    
    // Parar Web Speech API se estiver em uso
    if ('speechSynthesis' in window) {
      window.speechSynthesis.cancel();
    }
    
    setIsSpeaking(false);
  }, []);

  /**
   * Verificar permiss√£o de microfone
   */
  const checkMicrophonePermission = useCallback(async (): Promise<boolean> => {
    try {
      // Verificar se a API est√° dispon√≠vel
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        setError('API de m√≠dia n√£o suportada neste navegador');
        return false;
      }

      // Tentar verificar permiss√£o via API (pode n√£o estar dispon√≠vel em todos os navegadores)
      try {
        const permissionStatus = await navigator.permissions.query({ name: 'microphone' as PermissionName });
        
        if (permissionStatus.state === 'denied') {
          setError('Permiss√£o de microfone negada. Clique no √≠cone de cadeado na barra de endere√ßos e permita o acesso ao microfone.');
          return false;
        }
        
        // Se a permiss√£o j√° foi concedida, retornar true
        if (permissionStatus.state === 'granted') {
          return true;
        }
      } catch (permErr) {
        // Se n√£o conseguir verificar permiss√£o (navegador n√£o suporta), tentar acessar diretamente
        console.log('[STT] N√£o foi poss√≠vel verificar permiss√£o via API, tentando acessar diretamente...');
      }

      // Tentar acessar o microfone diretamente para verificar permiss√£o
      // Isso vai solicitar permiss√£o se ainda n√£o foi concedida
      try {
        const testStream = await navigator.mediaDevices.getUserMedia({ 
          audio: { 
            echoCancellation: true, 
            noiseSuppression: true, 
            autoGainControl: true 
          } 
        });
        // Se chegou aqui, a permiss√£o foi concedida
        testStream.getTracks().forEach(track => track.stop()); // Parar stream de teste
        return true;
      } catch (err: any) {
        if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {
          setError('Permiss√£o de microfone negada. Clique no √≠cone de cadeado na barra de endere√ßos e permita o acesso ao microfone.');
          return false;
        }
        throw err; // Re-lan√ßar outros erros
      }
    } catch (err) {
      console.warn('[STT] Erro ao verificar permiss√£o:', err);
      const errorMessage = err instanceof Error ? err.message : String(err);
      if (errorMessage.includes('Permission denied') || errorMessage.includes('NotAllowedError')) {
        setError('Permiss√£o de microfone negada. Clique no √≠cone de cadeado na barra de endere√ßos e permita o acesso ao microfone.');
        return false;
      }
      // Se n√£o for erro de permiss√£o, tentar mesmo assim
      return true;
    }
  }, []);

  /**
   * Iniciar grava√ß√£o de voz (STT)
   */
  const startListening = useCallback(async () => {
    // Prote√ß√£o contra m√∫ltiplas chamadas simult√¢neas
    if (!sttEnabled || isRecording || isStartingRef.current) {
      console.log('[STT] ‚ö†Ô∏è Grava√ß√£o j√° em andamento ou iniciando, ignorando chamada duplicada');
      return;
    }

    try {
      isStartingRef.current = true; // Marcar que est√° iniciando
      setError(null);
      console.log('[STT] Iniciando grava√ß√£o...');

      // Verificar permiss√£o primeiro (mas n√£o bloquear se n√£o conseguir verificar)
      try {
        const hasPermission = await checkMicrophonePermission();
        if (!hasPermission) {
          console.warn('[STT] Permiss√£o n√£o concedida, mas tentando mesmo assim...');
          // N√£o retornar aqui - tentar acessar diretamente pode solicitar permiss√£o
        }
      } catch (permErr) {
        console.warn('[STT] Erro ao verificar permiss√£o, tentando acessar diretamente:', permErr);
        // Continuar mesmo se a verifica√ß√£o de permiss√£o falhar
      }

      // Solicitar acesso ao microfone
      let stream: MediaStream;
      try {
        stream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
          } 
        });
      } catch (err: any) {
        // Tratar erros espec√≠ficos de permiss√£o
        if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {
          setError('Permiss√£o de microfone negada. Clique no √≠cone de cadeado na barra de endere√ßos e permita o acesso ao microfone.');
          return;
        } else if (err.name === 'NotFoundError' || err.name === 'DevicesNotFoundError') {
          setError('Nenhum microfone encontrado. Verifique se o microfone est√° conectado.');
          return;
        } else if (err.name === 'NotReadableError' || err.name === 'TrackStartError') {
          setError('Erro ao acessar o microfone. Verifique se n√£o est√° sendo usado por outro aplicativo.');
          return;
        } else {
          throw err;
        }
      }

      // Verificar formato de √°udio suportado
      const mimeTypes = [
        'audio/webm;codecs=opus',
        'audio/webm',
        'audio/ogg;codecs=opus',
        'audio/mp4',
        'audio/mpeg',
      ];
      
      let supportedMimeType = mimeTypes.find(type => MediaRecorder.isTypeSupported(type));
      if (!supportedMimeType) {
        // Se nenhum formato espec√≠fico for suportado, tentar criar sem especificar (navegador escolhe)
        console.warn('[STT] Nenhum formato espec√≠fico suportado, usando formato padr√£o do navegador');
        supportedMimeType = undefined; // Deixar navegador escolher
      } else {
        console.log(`[STT] Usando formato: ${supportedMimeType}`);
      }

      // Criar MediaRecorder com formato suportado (ou formato padr√£o)
      const mediaRecorder = new MediaRecorder(stream, supportedMimeType ? {
        mimeType: supportedMimeType,
      } : undefined);

      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data && event.data.size > 0) {
          audioChunksRef.current.push(event.data);
          console.log(`[STT] Dados de √°udio recebidos: ${event.data.size} bytes`);
        }
      };

      mediaRecorder.onerror = (event) => {
        console.error('[STT] Erro no MediaRecorder:', event);
        setError('Erro ao gravar √°udio. Tente novamente.');
        stream.getTracks().forEach(track => track.stop());
        setIsRecording(false);
        setIsListening(false);
        isStartingRef.current = false;
      };

      mediaRecorder.onstop = async () => {
        try {
          console.log(`[STT] Grava√ß√£o parada. Total de chunks: ${audioChunksRef.current.length}`);
          
          // Determinar tipo MIME do blob
          const blobType = supportedMimeType || 'audio/webm';
          const audioBlob = new Blob(audioChunksRef.current, { type: blobType });
          
          console.log(`[STT] Blob criado: ${audioBlob.size} bytes, tipo: ${blobType}`);
          
          if (audioBlob.size === 0) {
            throw new Error('√Åudio vazio. Tente falar mais alto ou verifique o microfone.');
          }
          
          // Enviar para API de STT
          const formData = new FormData();
          const fileExtension = blobType.includes('webm') ? 'webm' : 
                                blobType.includes('ogg') ? 'ogg' : 
                                blobType.includes('mp4') || blobType.includes('mpeg') ? 'mp4' : 'webm';
          formData.append('audio', audioBlob, `recording.${fileExtension}`);

          console.log(`[STT] Enviando √°udio para API: ${audioBlob.size} bytes`);
          const response = await fetch('/api/stt', {
            method: 'POST',
            body: formData,
          });

          console.log(`[STT] Resposta recebida: status=${response.status}, ok=${response.ok}`);

          if (!response.ok) {
            let errorMessage = 'Erro ao processar √°udio';
            try {
              const errorData = await response.json();
              errorMessage = errorData.error || errorData.details || errorMessage;
              console.error(`[STT] ‚ùå Erro da API:`, errorData);
            } catch {
              try {
                const errorText = await response.text();
                errorMessage = errorText || errorMessage;
                console.error(`[STT] ‚ùå Erro da API (texto):`, errorText);
              } catch {
                console.error(`[STT] ‚ùå Erro desconhecido da API`);
              }
            }
            throw new Error(errorMessage);
          }

          const data = await response.json();
          console.log(`[STT] ‚úÖ Dados recebidos:`, data);
          
          if (data.text && data.text.trim()) {
            // Verificar se n√£o √© mensagem de "n√£o implementado" ou erro de depend√™ncia
            if (data.text.includes('ainda n√£o implementada') || 
                data.text.includes('ainda n√£o implementado') ||
                data.error === 'STT n√£o dispon√≠vel') {
              const errorMsg = data.solution 
                ? `STT n√£o dispon√≠vel. ${data.suggestion || 'Instale as depend√™ncias do STT.'}`
                : 'STT ainda n√£o est√° completamente implementado. Use texto por enquanto.';
              setError(errorMsg);
              console.warn('[STT] ‚ö†Ô∏è STT n√£o dispon√≠vel:', data);
            } else {
              console.log(`[STT] ‚úÖ Texto transcrito: "${data.text}"`);
              onTextReceived?.(data.text);
              setError(null); // Limpar erro se sucesso
            }
          } else if (data.error) {
            // Se houver erro na resposta, mostrar mensagem amig√°vel
            const errorMsg = data.suggestion || data.details || data.error || 'Erro ao processar √°udio';
            setError(errorMsg);
            console.error('[STT] ‚ùå Erro na resposta:', data);
          } else {
            setError('N√£o foi poss√≠vel transcrever o √°udio. Tente novamente.');
            console.warn('[STT] ‚ö†Ô∏è Resposta vazia ou sem texto');
          }
        } catch (err) {
          console.error('‚ùå Erro ao processar √°udio:', err);
          const errorMessage = err instanceof Error ? err.message : 'Erro ao processar √°udio';
          setError(errorMessage);
        } finally {
          // Parar todas as tracks
          stream.getTracks().forEach(track => {
            track.stop();
            console.log('[STT] Track parado:', track.label);
          });
          setIsRecording(false);
          setIsListening(false);
          isStartingRef.current = false; // Resetar flag
        }
      };

      // Iniciar grava√ß√£o
      console.log('[STT] Iniciando grava√ß√£o...');
      mediaRecorder.start(1000); // Coletar dados a cada 1 segundo
      mediaRecorderRef.current = mediaRecorder;
      setIsRecording(true);
      setIsListening(true);
      isStartingRef.current = false; // Marcar que iniciou com sucesso
      setError(null); // Limpar erros anteriores
    } catch (err) {
      console.error('‚ùå Erro ao iniciar grava√ß√£o:', err);
      isStartingRef.current = false; // Resetar flag em caso de erro
      
      const errorMessage = err instanceof Error ? err.message : 'Erro ao acessar microfone';
      const errorName = err instanceof Error ? (err as any).name : '';
      
      // Mensagens mais espec√≠ficas baseadas no tipo de erro
      if (errorName === 'NotAllowedError' || errorName === 'PermissionDeniedError' || errorMessage.includes('Permission denied')) {
        setError('Permiss√£o de microfone negada. Clique no √≠cone de cadeado na barra de endere√ßos e permita o acesso ao microfone.');
      } else if (errorName === 'NotFoundError' || errorName === 'DevicesNotFoundError' || errorMessage.includes('No microphone')) {
        setError('Nenhum microfone encontrado. Verifique se o microfone est√° conectado e funcionando.');
      } else if (errorName === 'NotReadableError' || errorName === 'TrackStartError' || errorMessage.includes('not readable')) {
        setError('Erro ao acessar o microfone. Verifique se n√£o est√° sendo usado por outro aplicativo.');
      } else if (errorName === 'OverconstrainedError' || errorMessage.includes('constraint')) {
        setError('Configura√ß√µes de √°udio n√£o suportadas. Tentando com configura√ß√µes padr√£o...');
        // Tentar novamente com configura√ß√µes mais simples
        setTimeout(() => {
          startListening();
        }, 500);
        return;
      } else {
        setError(`Erro ao acessar microfone: ${errorMessage}`);
      }
      
      setIsRecording(false);
      setIsListening(false);
    }
  }, [sttEnabled, isRecording, onTextReceived, checkMicrophonePermission]);

  /**
   * Parar grava√ß√£o de voz
   */
  const stopListening = useCallback(() => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      mediaRecorderRef.current = null;
    }
  }, [isRecording]);

  /**
   * Toggle grava√ß√£o
   */
  const toggleListening = useCallback(() => {
    if (isRecording) {
      stopListening();
    } else {
      startListening();
    }
  }, [isRecording, startListening, stopListening]);

  return {
    // TTS
    speak,
    stopSpeaking,
    isSpeaking,
    
    // STT
    startListening,
    stopListening,
    toggleListening,
    isRecording,
    isListening,
    
    // Estado
    error,
    setError, // Expor setError para poder limpar erros manualmente
  };
}


