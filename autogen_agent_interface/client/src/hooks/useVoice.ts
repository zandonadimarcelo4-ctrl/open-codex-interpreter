/**
 * Hook para Voz Jarvis (TTS) e Speech-to-Text (STT)
 */
import { useState, useRef, useCallback, useEffect } from 'react';

export interface UseVoiceOptions {
  ttsEnabled?: boolean;
  sttEnabled?: boolean;
  onTextReceived?: (text: string) => void;
  onAudioReady?: (audioUrl: string) => void;
}

export function useVoice(options: UseVoiceOptions = {}) {
  const {
    ttsEnabled = true,
    sttEnabled = true,
    onTextReceived,
    onAudioReady,
  } = options;

  const [isRecording, setIsRecording] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const audioContextRef = useRef<AudioContext | null>(null);
  const audioElementRef = useRef<HTMLAudioElement | null>(null);

  // Inicializar √°udio element
  useEffect(() => {
    audioElementRef.current = new Audio();
    audioElementRef.current.onended = () => setIsSpeaking(false);
    audioElementRef.current.onerror = () => {
      setIsSpeaking(false);
      setError('Erro ao reproduzir √°udio');
    };

    return () => {
      if (audioElementRef.current) {
        audioElementRef.current.pause();
        audioElementRef.current = null;
      }
      if (audioContextRef.current) {
        audioContextRef.current.close();
        audioContextRef.current = null;
      }
    };
  }, []);

  /**
   * Reproduzir √°udio TTS (Text-to-Speech)
   */
  const speak = useCallback(async (text: string) => {
    if (!ttsEnabled || !text.trim()) {
      console.log('[TTS] TTS desabilitado ou texto vazio, ignorando');
      return;
    }

    // Parar qualquer √°udio anterior antes de iniciar um novo
    if (audioElementRef.current) {
      try {
        audioElementRef.current.pause();
        audioElementRef.current.currentTime = 0;
        audioElementRef.current.src = '';
      } catch (e) {
        // Ignorar erros ao parar √°udio anterior
      }
    }

    // Se j√° est√° falando, parar antes de iniciar novo
    if (isSpeaking) {
      console.log('[TTS] Parando √°udio anterior antes de iniciar novo');
      setIsSpeaking(false);
      // Aguardar um pouco para garantir que o √°udio anterior parou
      await new Promise(resolve => setTimeout(resolve, 100));
    }

    try {
      setIsSpeaking(true);
      setError(null);

      // Limpar texto removendo emojis e caracteres especiais antes de enviar
      // Remover TODOS os caracteres Unicode acima de 0x7F exceto acentos portugueses
      let cleanedText = text.split('').filter(char => {
        const code = char.charCodeAt(0);
        // Manter apenas ASCII b√°sico (0-127) e acentos portugueses (0x00C0-0x017F)
        return code <= 0x7F || (code >= 0x00C0 && code <= 0x017F);
      }).join('');
      
      // Remover markdown e caracteres especiais
      cleanedText = cleanedText.replace(/#{1,6}\s+/g, ''); // Headers
      cleanedText = cleanedText.replace(/\*\*/g, ''); // Bold
      cleanedText = cleanedText.replace(/\*/g, ''); // Italic
      cleanedText = cleanedText.replace(/__/g, ''); // Bold
      cleanedText = cleanedText.replace(/_/g, ''); // Italic
      cleanedText = cleanedText.replace(/`/g, ''); // Code
      cleanedText = cleanedText.replace(/\[([^\]]+)\]\([^\)]+\)/g, '$1'); // Links
      cleanedText = cleanedText.replace(/!\[([^\]]*)\]\([^\)]+\)/g, ''); // Images
      cleanedText = cleanedText.replace(/[^\x00-\x7F\u00C0-\u017F\s.,!?;:()\-]/g, ' '); // Remover caracteres especiais
      cleanedText = cleanedText.replace(/\s+/g, ' ').trim(); // Normalizar espa√ßos
      
      if (!cleanedText.trim()) {
        console.warn('‚ö†Ô∏è Texto vazio ap√≥s limpeza, n√£o enviando para TTS');
        setIsSpeaking(false);
        return;
      }

      // Usar APENAS API de TTS do backend (ElevenLabs/Piper)
      console.log('üéôÔ∏è Tentando usar API de TTS do backend (ElevenLabs/Piper)...');
      console.log(`üìù Texto original (${text.length} chars) -> Limpo (${cleanedText.length} chars)`);
      console.log(`üìù Texto limpo (primeiros 100 chars): ${cleanedText.substring(0, 100)}`);
      
      try {
        const apiUrl = '/api/tts';
        console.log(`[TTS] Enviando requisi√ß√£o para: ${apiUrl}`);
        console.log(`[TTS] Texto a ser enviado: ${cleanedText.substring(0, 200)}...`);
        
        const response = await fetch(apiUrl, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({ text: cleanedText }),
        });
        
        console.log(`[TTS] Resposta recebida: status=${response.status}, ok=${response.ok}, contentType=${response.headers.get('content-type')}`);

        if (response.ok) {
          const contentType = response.headers.get('content-type');
          console.log(`[TTS] Content-Type recebido: ${contentType}`);
          
          // Verificar se √© realmente √°udio
          if (!contentType || !contentType.startsWith('audio/')) {
            console.warn(`[TTS] ‚ö†Ô∏è Content-Type inesperado: ${contentType}, tentando processar como √°udio mesmo assim`);
          }
          
          const audioBlob = await response.blob();
          console.log(`[TTS] Blob recebido: tamanho=${audioBlob.size} bytes, type=${audioBlob.type}`);
          
          if (audioBlob.size === 0) {
            throw new Error('√Åudio recebido est√° vazio (0 bytes)');
          }
          
          const audioUrl = URL.createObjectURL(audioBlob);
          console.log(`[TTS] ‚úÖ √Åudio recebido do backend TTS (ElevenLabs/Piper), tamanho: ${audioBlob.size} bytes`);

          if (!audioElementRef.current) {
            console.error('[TTS] ‚ùå audioElementRef.current √© null');
            setIsSpeaking(false);
            URL.revokeObjectURL(audioUrl);
            throw new Error('Elemento de √°udio n√£o est√° dispon√≠vel');
          }

          // Parar e limpar elemento anterior se existir
          if (audioElementRef.current) {
            try {
              audioElementRef.current.pause();
              audioElementRef.current.currentTime = 0;
              audioElementRef.current.src = '';
              // Remover todos os event listeners
              audioElementRef.current.onended = null;
              audioElementRef.current.onerror = null;
              audioElementRef.current.onloadeddata = null;
              audioElementRef.current.onloadstart = null;
            } catch (e) {
              // Ignorar erros
            }
          }

          // Criar novo elemento de √°udio (n√£o clonar para evitar problemas)
          const newAudioElement = new Audio();
          audioElementRef.current = newAudioElement;
          
          // Flag para garantir que s√≥ reproduz uma vez
          let hasPlayed = false;
          
          newAudioElement.src = audioUrl;
          
          // Configurar event listeners
          newAudioElement.onended = () => {
            console.log('[TTS] ‚úÖ √Åudio reproduzido com sucesso');
            setIsSpeaking(false);
            hasPlayed = false;
            URL.revokeObjectURL(audioUrl);
          };
          
          newAudioElement.onerror = (error) => {
            console.error('‚ùå Erro ao reproduzir √°udio:', error);
            console.error(`[TTS] Erro no elemento de √°udio:`, newAudioElement.error);
            setIsSpeaking(false);
            hasPlayed = false;
            const errorMsg = newAudioElement.error 
              ? `Erro ao reproduzir √°udio: ${newAudioElement.error.message || 'Erro desconhecido'}`
              : 'Erro ao reproduzir √°udio. Verifique se o formato de √°udio √© suportado.';
            setError(errorMsg);
            URL.revokeObjectURL(audioUrl);
          };
          
          newAudioElement.onloadeddata = async () => {
            // S√≥ reproduzir se ainda n√£o reproduziu
            if (!hasPlayed) {
              console.log('[TTS] √Åudio carregado, tentando reproduzir...');
              try {
                hasPlayed = true;
                await newAudioElement.play();
                console.log('[TTS] ‚úÖ √Åudio reproduzido com sucesso');
                onAudioReady?.(audioUrl);
              } catch (playError) {
                hasPlayed = false;
                console.error('‚ùå Erro ao reproduzir √°udio:', playError);
                setIsSpeaking(false);
                const errorMsg = playError instanceof Error 
                  ? `Erro ao reproduzir √°udio: ${playError.message}`
                  : 'Erro ao reproduzir √°udio. Verifique as permiss√µes do navegador.';
                setError(errorMsg);
                URL.revokeObjectURL(audioUrl);
              }
            }
          };
          
          newAudioElement.onloadstart = () => {
            console.log('[TTS] Iniciando carregamento do √°udio...');
          };
          
          // Se o √°udio j√° estiver carregado, reproduzir imediatamente (mas s√≥ uma vez)
          if (newAudioElement.readyState >= 2 && !hasPlayed) {
            console.log(`[TTS] √Åudio j√° carregado (readyState=${newAudioElement.readyState}), reproduzindo imediatamente...`);
            try {
              hasPlayed = true;
              await newAudioElement.play();
              console.log('[TTS] ‚úÖ √Åudio reproduzido com sucesso');
              onAudioReady?.(audioUrl);
            } catch (playError) {
              hasPlayed = false;
              console.error('‚ùå Erro ao reproduzir √°udio:', playError);
              setIsSpeaking(false);
              const errorMsg = playError instanceof Error 
                ? `Erro ao reproduzir √°udio: ${playError.message}`
                : 'Erro ao reproduzir √°udio. Verifique as permiss√µes do navegador.';
              setError(errorMsg);
              URL.revokeObjectURL(audioUrl);
            }
          } else {
            // Aguardar o √°udio carregar
            console.log(`[TTS] √Åudio ainda n√£o carregado (readyState=${newAudioElement.readyState}), aguardando...`);
          }
          
          return;
        } else {
          // Tentar ler como JSON primeiro, depois como texto
          let errorText = '';
          try {
            const errorJson = await response.json();
            errorText = errorJson.error || JSON.stringify(errorJson);
          } catch {
            // Se n√£o for JSON, ler como texto
            errorText = await response.text();
            // Se for HTML (p√°gina de erro), extrair mensagem √∫til
            if (errorText.includes('<!doctype') || errorText.includes('<html')) {
              errorText = `Erro ${response.status}: P√°gina de erro HTML retornada (rota n√£o encontrada?)`;
            }
          }
          console.error('‚ùå Erro na API de TTS:', response.status, errorText);
          setError(`Erro na API de TTS: ${response.status} - ${errorText.substring(0, 100)}`);
          throw new Error(`API de TTS retornou erro: ${response.status}`);
        }
      } catch (apiError) {
        console.error('‚ùå Erro ao chamar API de TTS:', apiError);
        setError('Erro ao chamar API de TTS. Verifique se o backend est√° rodando e se ElevenLabs est√° configurado.');
        throw apiError; // N√£o usar fallback - for√ßar uso do backend
      }

      // REMOVIDO: Fallback para Web Speech API (soa como Google Tradutor)
      // Usar APENAS ElevenLabs/Piper do backend
      throw new Error('TTS n√£o dispon√≠vel: API do backend n√£o respondeu corretamente');
      
      // C√ìDIGO COMENTADO - N√£o usar Web Speech API
      /*
      // Fallback para Web Speech API
          if ('speechSynthesis' in window) {
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'pt-BR';  // FOR√áAR portugu√™s brasileiro
            utterance.rate = 0.92;  // Ligeiramente mais lento para soar mais natural
            utterance.pitch = 1.0;
            utterance.volume = 1.0;
            
            // Tentar usar voz neural mais natural se dispon√≠vel
            const voices = window.speechSynthesis.getVoices();
            // Priorizar vozes neurais brasileiras
            const ptBRVoice = voices.find((v: SpeechSynthesisVoice) => 
              v.lang === 'pt-BR' && (v.name.includes('Neural') || v.name.includes('Google') || v.name.includes('Brazil'))
            ) || voices.find((v: SpeechSynthesisVoice) => 
              v.lang.startsWith('pt-BR')
            ) || voices.find((v: SpeechSynthesisVoice) => 
              v.lang.startsWith('pt')
            );
            if (ptBRVoice) {
              utterance.voice = ptBRVoice;
              utterance.lang = ptBRVoice.lang;  // Usar idioma da voz selecionada
            }
        
        utterance.onend = () => setIsSpeaking(false);
        utterance.onerror = (err) => {
          console.error('Erro na Web Speech API:', err);
          setError('Erro ao reproduzir √°udio com Web Speech API');
          setIsSpeaking(false);
        };
        
        window.speechSynthesis.speak(utterance);
      } else {
        throw new Error('TTS n√£o dispon√≠vel: API n√£o encontrada e Web Speech API n√£o suportada');
      }
      */
    } catch (err) {
      console.error('Erro ao falar:', err);
      setError(err instanceof Error ? err.message : 'Erro ao reproduzir √°udio');
      setIsSpeaking(false);
    }
  }, [ttsEnabled, onAudioReady]);

  /**
   * Parar de falar
   */
  const stopSpeaking = useCallback(() => {
    if (audioElementRef.current) {
      audioElementRef.current.pause();
      audioElementRef.current.currentTime = 0;
    }
    
    // Parar Web Speech API se estiver em uso
    if ('speechSynthesis' in window) {
      window.speechSynthesis.cancel();
    }
    
    setIsSpeaking(false);
  }, []);

  /**
   * Verificar permiss√£o de microfone
   */
  const checkMicrophonePermission = useCallback(async (): Promise<boolean> => {
    try {
      // Verificar se a API est√° dispon√≠vel
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        setError('API de m√≠dia n√£o suportada neste navegador');
        return false;
      }

      // Verificar permiss√£o
      const permissionStatus = await navigator.permissions.query({ name: 'microphone' as PermissionName });
      
      if (permissionStatus.state === 'denied') {
        setError('Permiss√£o de microfone negada. Por favor, permita o acesso nas configura√ß√µes do navegador.');
        return false;
      }

      return true;
    } catch (err) {
      // Se a API de permiss√µes n√£o estiver dispon√≠vel, tentar acessar diretamente
      console.warn('N√£o foi poss√≠vel verificar permiss√£o:', err);
      return true;
    }
  }, []);

  /**
   * Iniciar grava√ß√£o de voz (STT)
   */
  const startListening = useCallback(async () => {
    if (!sttEnabled || isRecording) return;

    try {
      setError(null);

      // Verificar permiss√£o primeiro
      const hasPermission = await checkMicrophonePermission();
      if (!hasPermission) {
        return;
      }

      // Solicitar acesso ao microfone
      let stream: MediaStream;
      try {
        stream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
          } 
        });
      } catch (err: any) {
        // Tratar erros espec√≠ficos de permiss√£o
        if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {
          setError('Permiss√£o de microfone negada. Clique no √≠cone de cadeado na barra de endere√ßos e permita o acesso ao microfone.');
          return;
        } else if (err.name === 'NotFoundError' || err.name === 'DevicesNotFoundError') {
          setError('Nenhum microfone encontrado. Verifique se o microfone est√° conectado.');
          return;
        } else if (err.name === 'NotReadableError' || err.name === 'TrackStartError') {
          setError('Erro ao acessar o microfone. Verifique se n√£o est√° sendo usado por outro aplicativo.');
          return;
        } else {
          throw err;
        }
      }

      // Verificar se MediaRecorder est√° dispon√≠vel
      if (!MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
        // Fallback para outros formatos
        const mimeTypes = [
          'audio/webm;codecs=opus',
          'audio/webm',
          'audio/ogg;codecs=opus',
          'audio/mp4',
        ];
        
        let supportedMimeType = mimeTypes.find(type => MediaRecorder.isTypeSupported(type));
        if (!supportedMimeType) {
          setError('Formato de √°udio n√£o suportado neste navegador');
          stream.getTracks().forEach(track => track.stop());
          return;
        }

        const mediaRecorder = new MediaRecorder(stream, {
          mimeType: supportedMimeType,
        });

        audioChunksRef.current = [];

        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            audioChunksRef.current.push(event.data);
          }
        };

        mediaRecorder.onstop = async () => {
          try {
            const audioBlob = new Blob(audioChunksRef.current, { type: supportedMimeType || 'audio/webm' });
            
            // Enviar para API de STT
            const formData = new FormData();
            formData.append('audio', audioBlob, `recording.${supportedMimeType?.split('/')[1]?.split(';')[0] || 'webm'}`);

            const response = await fetch('/api/stt', {
              method: 'POST',
              body: formData,
            });

            if (!response.ok) {
              throw new Error('Erro ao processar √°udio');
            }

            const data = await response.json();
            if (data.text) {
              onTextReceived?.(data.text);
            } else {
              setError('N√£o foi poss√≠vel transcrever o √°udio. Tente novamente.');
            }
          } catch (err) {
            console.error('Erro ao processar √°udio:', err);
            setError(err instanceof Error ? err.message : 'Erro ao processar √°udio');
          } finally {
            // Parar todas as tracks
            stream.getTracks().forEach(track => track.stop());
            setIsRecording(false);
            setIsListening(false);
          }
        };

        mediaRecorder.start();
        mediaRecorderRef.current = mediaRecorder;
        setIsRecording(true);
        setIsListening(true);
      } else {
        const mediaRecorder = new MediaRecorder(stream, {
          mimeType: 'audio/webm;codecs=opus',
        });

        audioChunksRef.current = [];

        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            audioChunksRef.current.push(event.data);
          }
        };

        mediaRecorder.onstop = async () => {
          try {
            const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
            
            // Enviar para API de STT
            const formData = new FormData();
            formData.append('audio', audioBlob, 'recording.webm');

            const response = await fetch('/api/stt', {
              method: 'POST',
              body: formData,
            });

            if (!response.ok) {
              throw new Error('Erro ao processar √°udio');
            }

            const data = await response.json();
            if (data.text) {
              onTextReceived?.(data.text);
            } else {
              setError('N√£o foi poss√≠vel transcrever o √°udio. Tente novamente.');
            }
          } catch (err) {
            console.error('Erro ao processar √°udio:', err);
            setError(err instanceof Error ? err.message : 'Erro ao processar √°udio');
          } finally {
            // Parar todas as tracks
            stream.getTracks().forEach(track => track.stop());
            setIsRecording(false);
            setIsListening(false);
          }
        };

        mediaRecorder.start();
        mediaRecorderRef.current = mediaRecorder;
        setIsRecording(true);
        setIsListening(true);
      }
    } catch (err) {
      console.error('Erro ao iniciar grava√ß√£o:', err);
      const errorMessage = err instanceof Error ? err.message : 'Erro ao acessar microfone';
      
      // Mensagens mais espec√≠ficas
      if (errorMessage.includes('Permission denied') || errorMessage.includes('NotAllowedError')) {
        setError('Permiss√£o de microfone negada. Clique no √≠cone de cadeado na barra de endere√ßos e permita o acesso ao microfone.');
      } else if (errorMessage.includes('NotFoundError')) {
        setError('Nenhum microfone encontrado. Verifique se o microfone est√° conectado.');
      } else {
        setError(errorMessage);
      }
      
      setIsRecording(false);
      setIsListening(false);
    }
  }, [sttEnabled, isRecording, onTextReceived, checkMicrophonePermission]);

  /**
   * Parar grava√ß√£o de voz
   */
  const stopListening = useCallback(() => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      mediaRecorderRef.current = null;
    }
  }, [isRecording]);

  /**
   * Toggle grava√ß√£o
   */
  const toggleListening = useCallback(() => {
    if (isRecording) {
      stopListening();
    } else {
      startListening();
    }
  }, [isRecording, startListening, stopListening]);

  return {
    // TTS
    speak,
    stopSpeaking,
    isSpeaking,
    
    // STT
    startListening,
    stopListening,
    toggleListening,
    isRecording,
    isListening,
    
    // Estado
    error,
  };
}


