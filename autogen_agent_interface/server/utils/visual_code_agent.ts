/**
 * Visual Code Agent - Agente de Gera√ß√£o de C√≥digo a Partir de Imagens
 * 
 * Capacidades:
 * - An√°lise de imagens de c√≥digo
 * - Gera√ß√£o de c√≥digo a partir de screenshots
 * - An√°lise visual de interfaces
 * - Extra√ß√£o de c√≥digo de imagens
 * - Integra√ß√£o com After Effects MCP (futuro)
 */

interface VisualCodeRequest {
  imageUrl: string; // URL ou base64 da imagem
  language?: string;
  description?: string;
  context?: string;
}

interface VisualCodeResult {
  code: string;
  language: string;
  confidence: number;
  extractedElements: Array<{ type: string; content: string; position?: { x: number; y: number; width: number; height: number } }>;
  suggestions: string[];
}

const OLLAMA_BASE_URL = process.env.OLLAMA_BASE_URL || "http://localhost:11434";
// Modelo quantizado otimizado para RTX NVIDIA (Q4_K_M)
const DEFAULT_MODEL = process.env.DEFAULT_MODEL || "deepseek-coder-v2-16b-q4_k_m-rtx";

/**
 * Analisar imagem e gerar c√≥digo
 */
export async function generateCodeFromImage(request: VisualCodeRequest): Promise<VisualCodeResult> {
  console.log(`[VisualCodeAgent] üñºÔ∏è Gerando c√≥digo a partir de imagem...`);
  
  // Verificar se o modelo suporta vis√£o (LLaVA, GPT-4 Vision, etc.)
  // Por enquanto, usar descri√ß√£o de texto se dispon√≠vel
  const prompt = request.description || "Extract code from this image and generate the equivalent code.";
  
  try {
    // Tentar usar modelo com vis√£o se dispon√≠vel
    const visionModels = ['llava', 'llava:13b', 'llava:7b', 'gpt-4-vision'];
    let model = DEFAULT_MODEL;
    
    // Verificar se h√° modelo de vis√£o dispon√≠vel
    for (const visionModel of visionModels) {
      try {
        const response = await fetch(`${OLLAMA_BASE_URL}/api/tags`);
        if (response.ok) {
          const data = await response.json();
          const models = data.models || [];
          if (models.some((m: any) => m.name.includes(visionModel))) {
            model = visionModel;
            break;
          }
        }
      } catch (error) {
        // Continuar
      }
    }
    
    // Se n√£o h√° modelo de vis√£o, usar descri√ß√£o de texto
    if (!visionModels.some(vm => model.includes(vm))) {
      console.log(`[VisualCodeAgent] ‚ö†Ô∏è Nenhum modelo de vis√£o dispon√≠vel, usando descri√ß√£o de texto`);
      
      if (!request.description) {
        throw new Error("No description provided and no vision model available");
      }
      
      // Usar Code Router para gerar c√≥digo baseado na descri√ß√£o
      const { generateCode, estimateCodeComplexity } = await import("./code_router");
      const language = request.language || 'python';
      const complexity = estimateCodeComplexity(request.description);
      
      const codeResult = await generateCode({
        description: request.description,
        language,
        context: request.context,
        complexity,
      });
      
      return {
        code: codeResult.code,
        language: codeResult.language,
        confidence: 0.7,
        extractedElements: [],
        suggestions: ["Code generated from text description (no vision model available)"],
      };
    }
    
    // Usar modelo de vis√£o
    const response = await fetch(`${OLLAMA_BASE_URL}/api/chat`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        model,
        messages: [
          {
            role: "user",
            content: prompt,
            images: [request.imageUrl], // Base64 ou URL
          }
        ],
        options: {
          temperature: 0.3,
          num_predict: 4096,
        },
      }),
    });

    if (!response.ok) {
      throw new Error(`Ollama API error: ${response.statusText}`);
    }

    const data = await response.json();
    const codeText = data.message?.content || "";
    
    // Extrair c√≥digo da resposta
    const codeMatch = codeText.match(/```[\s\S]*?```/);
    const code = codeMatch ? codeMatch[0].replace(/```\w*\n?/g, '').replace(/```/g, '').trim() : codeText.trim();
    
    // Detectar linguagem
    const languageMatch = codeText.match(/```(\w+)/);
    const language = languageMatch ? languageMatch[1] : (request.language || 'python');
    
    return {
      code,
      language,
      confidence: 0.8,
      extractedElements: [],
      suggestions: ["Code extracted from image"],
    };
  } catch (error: any) {
    console.error(`[VisualCodeAgent] ‚ùå Erro ao gerar c√≥digo a partir de imagem:`, error);
    throw error;
  }
}

/**
 * Analisar interface e gerar c√≥digo
 */
export async function analyzeInterfaceAndGenerateCode(
  imageUrl: string,
  description: string,
  language: string = 'html'
): Promise<VisualCodeResult> {
  console.log(`[VisualCodeAgent] üé® Analisando interface e gerando c√≥digo...`);
  
  const prompt = `Analyze this UI/interface image and generate ${language} code to recreate it.

Description: ${description}

Requirements:
- Generate complete, working code
- Match the visual design
- Include all interactive elements
- Use modern best practices
- Make it responsive if applicable

Return the code in a code block.`;

  return generateCodeFromImage({
    imageUrl,
    language,
    description: prompt,
  });
}

/**
 * Extrair c√≥digo de screenshot
 */
export async function extractCodeFromScreenshot(
  imageUrl: string,
  language?: string
): Promise<VisualCodeResult> {
  console.log(`[VisualCodeAgent] üì∏ Extraindo c√≥digo de screenshot...`);
  
  const prompt = `Extract all code visible in this screenshot. 
  
If code blocks are visible, extract them exactly as shown.
If it's a code editor, extract the code being edited.
If it's documentation, extract code examples.

Return the extracted code in the appropriate language.`;

  return generateCodeFromImage({
    imageUrl,
    language,
    description: prompt,
  });
}

export { VisualCodeRequest, VisualCodeResult };

