# ğŸš€ ConfiguraÃ§Ã£o do Modelo Qwen2.5:14b

## âœ… Por que Qwen2.5:14b?

- âœ… **Suporta function calling (tools)** - Resolve o erro "does not support tools"
- âœ… **Muito inteligente** - Modelo de alta qualidade
- âœ… **Bom em cÃ³digo** - Especializado em programaÃ§Ã£o
- âœ… **Tamanho razoÃ¡vel** - ~8-9GB (cabe em 16GB VRAM)

## ğŸ“¥ InstalaÃ§Ã£o

### Windows
```bash
# Executar script de instalaÃ§Ã£o
scripts\setup_qwen2.5_14b.bat

# Ou manualmente
ollama pull qwen2.5:14b
```

### Linux/macOS
```bash
# Instalar manualmente
ollama pull qwen2.5:14b
```

## ğŸ”§ ConfiguraÃ§Ã£o

### 1. Atualizar `.env`
```env
DEFAULT_MODEL=qwen2.5:14b
```

### 2. Reiniciar o servidor
```bash
# Parar o servidor atual
# Reiniciar o servidor
```

## ğŸ¯ Alternativas

### Qwen2.5:32b (Mais Inteligente)
- âœ… Mais inteligente que 14b
- âŒ Maior (~20GB)
- âŒ Mais lento
- ğŸ’¡ Use se tiver 24GB+ VRAM

### Qwen2.5:7b (Mais RÃ¡pido)
- âœ… Mais rÃ¡pido que 14b
- âœ… Menor (~4GB)
- âŒ Menos inteligente
- ğŸ’¡ Use se precisar de velocidade

### Llama3.2:3b (Menor)
- âœ… Menor (~2GB)
- âœ… RÃ¡pido
- âŒ Menos inteligente
- ğŸ’¡ Use para testes rÃ¡pidos

## âœ… VerificaÃ§Ã£o

### Verificar se o modelo estÃ¡ instalado
```bash
ollama list | grep qwen2.5:14b
```

### Testar function calling
```bash
ollama run qwen2.5:14b "Execute um cÃ³digo Python que imprime 'Hello World'"
```

## ğŸ› Troubleshooting

### Erro: "model not found"
```bash
# Instalar o modelo
ollama pull qwen2.5:14b
```

### Erro: "out of memory"
```bash
# Usar modelo menor
DEFAULT_MODEL=qwen2.5:7b
```

### Erro: "still does not support tools"
```bash
# Verificar versÃ£o do Ollama (precisa ser >= 0.1.0)
ollama --version

# Atualizar Ollama
# Windows: Baixar de https://ollama.ai
# Linux: sudo apt update && sudo apt upgrade ollama
```

## ğŸ“Š ComparaÃ§Ã£o de Modelos

| Modelo | Tamanho | InteligÃªncia | Function Calling | Velocidade |
|--------|---------|--------------|------------------|------------|
| qwen2.5:32b | ~20GB | â­â­â­â­â­ | âœ… | â­â­ |
| qwen2.5:14b | ~8GB | â­â­â­â­ | âœ… | â­â­â­ |
| qwen2.5:7b | ~4GB | â­â­â­ | âœ… | â­â­â­â­ |
| llama3.2:3b | ~2GB | â­â­ | âœ… | â­â­â­â­â­ |

## ğŸ¯ RecomendaÃ§Ã£o

**Para a maioria dos casos:** `qwen2.5:14b`
- Balanceamento perfeito entre inteligÃªncia e velocidade
- Suporta function calling
- Cabe em 16GB VRAM

**Para desenvolvimento/testes:** `qwen2.5:7b`
- Mais rÃ¡pido
- Menor
- Ainda muito capaz

**Para produÃ§Ã£o mÃ¡xima:** `qwen2.5:32b`
- Mais inteligente
- Melhor qualidade
- Requer mais recursos

---

**Status:** âœ… Modelo configurado e pronto para usar!

