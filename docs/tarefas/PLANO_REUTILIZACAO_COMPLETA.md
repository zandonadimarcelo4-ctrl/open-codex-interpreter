# üéØ Plano Completo: Reutilizar Open Interpreter Dentro do AutoGen

## üìã Vis√£o Geral

**Objetivo:** Reutilizar 100% da l√≥gica do Open Interpreter dentro do AutoGen, mantendo todas as funcionalidades e usando o `model_client` do AutoGen.

**Abordagem:** Importar classe `Interpreter` do OI e adaptar m√©todo `respond()` para usar `model_client` do AutoGen, mantendo toda a l√≥gica de execu√ß√£o (CodeInterpreter, etc.).

---

## üó∫Ô∏è Plano de Implementa√ß√£o

### Fase 1: An√°lise e Prepara√ß√£o (1-2 horas)

#### 1.1 Analisar Estrutura do Open Interpreter
- [x] Identificar m√≥dulos principais:
  - `interpreter.py` - Classe principal
  - `code_interpreter.py` - Execu√ß√£o de c√≥digo
  - `code_block.py` - Display de blocos
  - `message_block.py` - Display de mensagens
  - `utils.py` - Utilit√°rios
  - `system_message.txt` - System message
- [x] Identificar depend√™ncias entre m√≥dulos
- [x] Identificar m√©todos cr√≠ticos:
  - `Interpreter.respond()` - Gera c√≥digo usando LLM
  - `Interpreter.chat()` - Loop principal de chat
  - `CodeInterpreter.run()` - Executa c√≥digo

#### 1.2 Analisar Interface do AutoGen
- [x] Entender `AssistantAgent` do AutoGen v2
- [x] Entender `model_client` do AutoGen
- [x] Entender sistema de mensagens do AutoGen
- [x] Identificar pontos de integra√ß√£o

#### 1.3 Definir Estrat√©gia de Adapta√ß√£o
- [x] **Estrat√©gia escolhida:** Substituir m√©todo `respond()` do Interpreter para usar `model_client` do AutoGen
- [x] Manter toda a l√≥gica de execu√ß√£o do OI (CodeInterpreter, etc.)
- [x] Manter system message do OI
- [x] Manter processamento de c√≥digo do OI

---

### Fase 2: Implementa√ß√£o do Agente (2-3 horas)

#### 2.1 Criar Agente Base

**Arquivo:** `super_agent/agents/open_interpreter_agent_integrated.py`

```python
"""
OpenInterpreterAgentIntegrated - Agente que reutiliza 100% da l√≥gica do Open Interpreter

Este agente importa a classe Interpreter do OI e adapta apenas o m√©todo respond()
para usar o model_client do AutoGen, mantendo toda a l√≥gica de execu√ß√£o do OI.
"""
import os
import sys
import logging
from pathlib import Path
from typing import Optional, Any, Dict, List

logger = logging.getLogger(__name__)

# Adicionar interpreter/ ao path
_current_dir = Path(__file__).parent
_interpreter_dir = _current_dir.parent.parent / "interpreter"
if _interpreter_dir.exists():
    sys.path.insert(0, str(_interpreter_dir.parent))

try:
    from autogen_agentchat.agents import AssistantAgent
    AUTOGEN_V2_AVAILABLE = True
except ImportError:
    AUTOGEN_V2_AVAILABLE = False
    logger.error("autogen-agentchat n√£o est√° instalado")

try:
    from interpreter.interpreter import Interpreter
    from interpreter.code_interpreter import CodeInterpreter
    from interpreter.utils import parse_partial_json, merge_deltas
    OPEN_INTERPRETER_AVAILABLE = True
except ImportError:
    OPEN_INTERPRETER_AVAILABLE = False
    logger.error("Open Interpreter n√£o dispon√≠vel")
```

#### 2.2 Criar Classe do Agente

```python
class OpenInterpreterAgentIntegrated(AssistantAgent):
    """
    Agente que reutiliza 100% da l√≥gica do Open Interpreter
    
    Caracter√≠sticas:
    - Importa classe Interpreter do OI
    - Substitui m√©todo respond() para usar model_client do AutoGen
    - Mant√©m toda a l√≥gica de execu√ß√£o do OI (CodeInterpreter, etc.)
    - Zero overhead de comunica√ß√£o (mesmo processo)
    """
    
    def __init__(
        self,
        name: str = "interpreter",
        model_client: Optional[Any] = None,
        workdir: Optional[str] = None,
        auto_run: bool = True,
        system_message: Optional[str] = None,
        **kwargs
    ):
        """
        Inicializa o agente integrado
        
        Args:
            name: Nome do agente
            model_client: Cliente LLM do AutoGen
            workdir: Diret√≥rio de trabalho (sandbox)
            auto_run: Executar c√≥digo automaticamente
            system_message: Mensagem do sistema personalizada
            **kwargs: Argumentos adicionais para AssistantAgent
        """
        if not AUTOGEN_V2_AVAILABLE:
            raise ImportError("autogen-agentchat n√£o est√° instalado")
        
        if not OPEN_INTERPRETER_AVAILABLE:
            raise ImportError("Open Interpreter n√£o dispon√≠vel")
        
        # Carregar system message do OI
        if system_message is None:
            system_message = self._load_system_message()
        
        # Inicializar AssistantAgent
        super().__init__(
            name=name,
            model_client=model_client,
            system_message=system_message,
            **kwargs
        )
        
        # Configura√ß√µes
        self.workdir = workdir or os.getcwd()
        self.auto_run = auto_run
        self.model_client_autogen = model_client
        
        # Criar inst√¢ncia do Interpreter do OI
        self.interpreter = Interpreter(
            auto_run=self.auto_run,
            local=True,  # Modo local
            model=None,  # Ser√° sobrescrito
            debug_mode=False,
            use_ollama=False,  # N√£o usar OllamaAdapter
        )
        
        # Desabilitar OllamaAdapter no Interpreter
        self.interpreter.ollama_adapter = None
        self.interpreter.use_ollama = False
        
        # Substituir m√©todo respond() do Interpreter
        # Salvar m√©todo original para refer√™ncia
        self._original_respond = self.interpreter.respond
        # Substituir por nossa implementa√ß√£o
        self.interpreter.respond = self._respond_with_autogen
        
        # Configurar workdir
        if self.workdir:
            os.makedirs(self.workdir, exist_ok=True)
        
        logger.info(f"‚úÖ OpenInterpreterAgentIntegrated inicializado")
        logger.info(f"   ‚úÖ Reutiliza 100% da l√≥gica do Open Interpreter")
        logger.info(f"   ‚úÖ Usa model_client do AutoGen")
        logger.info(f"   ‚úÖ Workdir: {self.workdir}")
```

#### 2.3 Implementar M√©todo _load_system_message()

```python
def _load_system_message(self) -> str:
    """Carrega system message do Open Interpreter"""
    try:
        system_message_path = _interpreter_dir / "system_message.txt"
        if system_message_path.exists():
            with open(system_message_path, 'r', encoding='utf-8') as f:
                return f.read()
    except Exception as e:
        logger.warning(f"N√£o foi poss√≠vel carregar system_message.txt: {e}")
    
    # Fallback para system message padr√£o
    return """You are Open Interpreter, a world-class programmer that can execute code on the user's machine.

First, write a plan. **Always recap the plan between each code block**.

When you execute code, it will be executed **on the user's machine**. The user has given you **full and complete permission** to execute any code necessary to complete the task.

Write code to solve the task. You can use any language, but Python is preferred.

When a user refers to a filename, they're likely referring to an existing file in the directory you're currently in.

When you want to give the user a final answer, use the print function to output it.

IMPORTANT: Execute code automatically. Do not ask for permission.
When you generate code, always include the code in markdown code blocks (```language\ncode\n```).
After generating code, the system will automatically execute it and return the results."""
```

#### 2.4 Implementar M√©todo _respond_with_autogen()

```python
def _respond_with_autogen(self):
    """
    Substitui respond() do Interpreter para usar model_client do AutoGen
    
    Este m√©todo:
    1. Prepara mensagens do Interpreter para o model_client do AutoGen
    2. Chama model_client do AutoGen (ass√≠ncrono)
    3. Processa resposta do LLM
    4. Extrai blocos de c√≥digo
    5. Executa c√≥digo usando CodeInterpreter do OI (reutiliza 100% da l√≥gica)
    6. Adiciona resultados √†s mensagens do Interpreter
    """
    import asyncio
    import re
    
    # Preparar mensagens para model_client do AutoGen
    messages = self.interpreter.messages.copy()
    
    # Adicionar system message se n√£o estiver presente
    has_system_message = any(msg.get("role") == "system" for msg in messages)
    if not has_system_message:
        system_message = self.interpreter.system_message
        if system_message:
            # Adicionar informa√ß√µes do sistema (como o OI faz)
            system_info = self.interpreter.get_info_for_system_message()
            full_system_message = system_message + system_info
            messages.insert(0, {"role": "system", "content": full_system_message})
    
    # Chamar model_client do AutoGen (ass√≠ncrono)
    try:
        # Executar de forma s√≠ncrona (o Interpreter espera resposta s√≠ncrona)
        if asyncio.iscoroutinefunction(self.model_client_autogen.create):
            # Se model_client √© ass√≠ncrono, usar loop existente ou criar novo
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    # Loop j√° est√° rodando, usar run_in_executor
                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(
                            asyncio.run,
                            self.model_client_autogen.create(messages=messages)
                        )
                        response = future.result()
                else:
                    response = loop.run_until_complete(
                        self.model_client_autogen.create(messages=messages)
                    )
            except RuntimeError:
                # N√£o h√° loop, criar novo
                response = asyncio.run(
                    self.model_client_autogen.create(messages=messages)
                )
        else:
            # Se model_client √© s√≠ncrono, chamar diretamente
            response = self.model_client_autogen.create(messages=messages)
        
        # Extrair conte√∫do da resposta
        if hasattr(response, 'choices'):
            # Formato OpenAI/AutoGen
            content = response.choices[0].message.content
        elif isinstance(response, dict):
            # Formato dict
            content = response.get("choices", [{}])[0].get("message", {}).get("content", "")
        else:
            content = str(response)
        
        # Adicionar resposta √†s mensagens do Interpreter
        self.interpreter.messages.append({
            "role": "assistant",
            "content": content
        })
        
        # Processar resposta: extrair c√≥digo e executar
        # Isso reutiliza 100% da l√≥gica do OI
        self._process_response(content)
        
    except Exception as e:
        logger.error(f"Erro ao chamar model_client do AutoGen: {e}")
        # Adicionar erro √†s mensagens
        self.interpreter.messages.append({
            "role": "assistant",
            "content": f"Erro ao processar: {str(e)}"
        })
```

#### 2.5 Implementar M√©todo _process_response()

```python
def _process_response(self, content: str):
    """
    Processa resposta do LLM: extrai c√≥digo e executa
    Reutiliza 100% da l√≥gica do Open Interpreter
    """
    import re
    
    # Extrair blocos de c√≥digo (mesma l√≥gica do OI)
    code_blocks = re.findall(r'```(\w+)?\n(.*?)```', content, re.DOTALL)
    
    if not code_blocks:
        return  # N√£o h√° c√≥digo para executar
    
    # Processar cada bloco de c√≥digo
    for language, code in code_blocks:
        language = language or "python"
        code = code.strip()
        
        if not code:
            continue
        
        # Executar c√≥digo usando CodeInterpreter do OI (reutiliza 100% da l√≥gica)
        try:
            output = self._execute_code(code, language)
            
            # Adicionar resultado √†s mensagens do Interpreter (formato do OI)
            self.interpreter.messages.append({
                "role": "function",
                "name": "run_code",
                "content": output
            })
            
        except Exception as e:
            logger.error(f"Erro ao executar c√≥digo: {e}")
            # Adicionar erro √†s mensagens
            self.interpreter.messages.append({
                "role": "function",
                "name": "run_code",
                "content": f"Erro ao executar c√≥digo: {str(e)}"
            })
```

#### 2.6 Implementar M√©todo _execute_code()

```python
def _execute_code(self, code: str, language: str) -> str:
    """
    Executa c√≥digo usando CodeInterpreter do OI (reutiliza 100% da l√≥gica)
    
    Args:
        code: C√≥digo a executar
        language: Linguagem do c√≥digo (python, shell, javascript, etc.)
    
    Returns:
        Output da execu√ß√£o
    """
    # Mudar para workdir
    original_cwd = os.getcwd()
    try:
        if self.workdir:
            os.chdir(self.workdir)
        
        # Obter ou criar CodeInterpreter para linguagem (reutiliza l√≥gica do OI)
        if language not in self.interpreter.code_interpreters:
            self.interpreter.code_interpreters[language] = CodeInterpreter(
                language=language,
                debug_mode=self.interpreter.debug_mode
            )
        
        code_interpreter = self.interpreter.code_interpreters[language]
        
        # Configurar c√≥digo no CodeInterpreter
        code_interpreter.code = code
        code_interpreter.language = language
        
        # Executar c√≥digo (reutiliza 100% da l√≥gica do OI)
        # CodeInterpreter.run() faz tudo:
        # - Inicia processo se necess√°rio
        - Adiciona active line tracking (AST transformation)
        # - Executa c√≥digo
        # - Captura output
        # - Retorna resultado
        output = code_interpreter.run()
        
        return output
        
    finally:
        os.chdir(original_cwd)
```

#### 2.7 Implementar M√©todo process_message() para AutoGen

```python
async def process_message(self, message: str) -> str:
    """
    Processa mensagem do AutoGen usando Interpreter do OI (reutiliza 100% da l√≥gica)
    
    Args:
        message: Mensagem do usu√°rio
    
    Returns:
        Resposta do agente
    """
    # Mudar para workdir
    original_cwd = os.getcwd()
    try:
        if self.workdir:
            os.chdir(self.workdir)
        
        # Adicionar mensagem ao Interpreter
        self.interpreter.messages.append({
            "role": "user",
            "content": message
        })
        
        # Chamar respond() do Interpreter (que foi substitu√≠do para usar model_client do AutoGen)
        # Isso vai:
        # 1. Chamar model_client do AutoGen (via _respond_with_autogen)
        # 2. Processar resposta (extrair c√≥digo)
        # 3. Executar c√≥digo (usando CodeInterpreter do OI)
        # 4. Adicionar resultados √†s mensagens
        self.interpreter.respond()
        
        # Extrair √∫ltima mensagem do Interpreter
        if self.interpreter.messages:
            # Buscar √∫ltima mensagem do assistant
            for msg in reversed(self.interpreter.messages):
                if msg.get("role") == "assistant":
                    return msg.get("content", "")
            
            # Se n√£o encontrou mensagem do assistant, retornar √∫ltima mensagem
            last_message = self.interpreter.messages[-1]
            return last_message.get("content", "C√≥digo executado com sucesso.")
        
        return "C√≥digo executado com sucesso."
        
    finally:
        os.chdir(original_cwd)
```

#### 2.8 Criar Fun√ß√£o Helper

```python
def create_open_interpreter_agent_integrated(
    model_client: Any,
    name: str = "interpreter",
    workdir: Optional[str] = None,
    auto_run: bool = True,
    **kwargs
) -> OpenInterpreterAgentIntegrated:
    """
    Cria um OpenInterpreterAgentIntegrated para uso no AutoGen
    
    Args:
        model_client: Cliente LLM do AutoGen
        name: Nome do agente
        workdir: Diret√≥rio de trabalho
        auto_run: Executar c√≥digo automaticamente
        **kwargs: Argumentos adicionais
    
    Returns:
        OpenInterpreterAgentIntegrated configurado
    """
    return OpenInterpreterAgentIntegrated(
        name=name,
        model_client=model_client,
        workdir=workdir,
        auto_run=auto_run,
        **kwargs
    )
```

---

### Fase 3: Integra√ß√£o com AutoGen (1-2 horas)

#### 3.1 Atualizar simple_commander.py

**Arquivo:** `super_agent/core/simple_commander.py`

```python
# Adicionar import
from ..agents.open_interpreter_agent_integrated import create_open_interpreter_agent_integrated

# No m√©todo _initialize_agents(), adicionar op√ß√£o para usar agente integrado
def _initialize_agents(self):
    # ... c√≥digo existente ...
    
    # Op√ß√£o 1: Usar TOOL (atual) - Recomendado para projeto est√°tico
    if USE_TOOL_APPROACH:
        # ... c√≥digo existente do TOOL ...
        pass
    
    # Op√ß√£o 2: Usar Agente Integrado (reutiliza 100% da l√≥gica do OI)
    elif USE_INTEGRATED_AGENT:
        interpreter_agent = create_open_interpreter_agent_integrated(
            model_client=llm_client,
            name="interpreter",
            workdir=self.workdir,
            auto_run=True,
        )
        
        # Adicionar agente ao team
        agents.append(interpreter_agent)
        logger.info(f"‚úÖ Agente integrado registrado: interpreter (reutiliza 100% da l√≥gica do OI)")
```

#### 3.2 Adicionar Configura√ß√£o

**Arquivo:** `super_agent/core/simple_commander.py`

```python
# Adicionar flag de configura√ß√£o
USE_INTEGRATED_AGENT = os.getenv("USE_INTEGRATED_INTERPRETER_AGENT", "false").lower() == "true"
USE_TOOL_APPROACH = not USE_INTEGRATED_AGENT  # TOOL √© padr√£o
```

---

### Fase 4: Testes (2-3 horas)

#### 4.1 Testes Unit√°rios

**Arquivo:** `tests/test_open_interpreter_agent_integrated.py`

```python
import pytest
from super_agent.agents.open_interpreter_agent_integrated import OpenInterpreterAgentIntegrated

def test_agent_initialization():
    """Testa inicializa√ß√£o do agente"""
    # ... testes ...

def test_code_execution():
    """Testa execu√ß√£o de c√≥digo Python"""
    # ... testes ...

def test_code_execution_shell():
    """Testa execu√ß√£o de c√≥digo Shell"""
    # ... testes ...

def test_code_execution_javascript():
    """Testa execu√ß√£o de c√≥digo JavaScript"""
    # ... testes ...
```

#### 4.2 Testes de Integra√ß√£o

**Arquivo:** `tests/test_integration_autogen_interpreter.py`

```python
def test_autogen_with_interpreter_agent():
    """Testa integra√ß√£o do agente com AutoGen"""
    # ... testes ...

def test_multiple_agents():
    """Testa m√∫ltiplos agentes trabalhando juntos"""
    # ... testes ...
```

#### 4.3 Testes de Performance

```python
def test_performance():
    """Testa performance do agente integrado"""
    # ... testes ...
    # Comparar com TOOL approach
```

---

### Fase 5: Documenta√ß√£o (1-2 horas)

#### 5.1 Documentar Agente

**Arquivo:** `docs/OPEN_INTERPRETER_AGENT_INTEGRATED.md`

```markdown
# OpenInterpreterAgentIntegrated

## Descri√ß√£o
Agente que reutiliza 100% da l√≥gica do Open Interpreter dentro do AutoGen.

## Uso
```python
from super_agent.agents.open_interpreter_agent_integrated import create_open_interpreter_agent_integrated

agent = create_open_interpreter_agent_integrated(
    model_client=llm_client,
    workdir="./workspace",
    auto_run=True,
)
```

## Caracter√≠sticas
- Reutiliza 100% da l√≥gica do Open Interpreter
- Usa model_client do AutoGen
- Zero overhead de comunica√ß√£o
- Funcionalidades completas (Python, Shell, JavaScript, HTML)
```

#### 5.2 Atualizar README

**Arquivo:** `README.md`

```markdown
## Open Interpreter Integration

### Op√ß√£o 1: TOOL (Recomendado)
- C√≥digo m√≠nimo (~100 linhas)
- Isolamento (processo separado)
- Performance adequada (overhead negligenci√°vel)

### Op√ß√£o 2: Agente Integrado
- Reutiliza 100% da l√≥gica do OI
- Zero overhead (mesmo processo)
- Integra√ß√£o nativa com AutoGen
```

---

## üìä Cronograma

| Fase | Tarefa | Tempo | Status |
|------|--------|-------|--------|
| 1 | An√°lise e Prepara√ß√£o | 1-2h | ‚è≥ Pendente |
| 2 | Implementa√ß√£o do Agente | 2-3h | ‚è≥ Pendente |
| 3 | Integra√ß√£o com AutoGen | 1-2h | ‚è≥ Pendente |
| 4 | Testes | 2-3h | ‚è≥ Pendente |
| 5 | Documenta√ß√£o | 1-2h | ‚è≥ Pendente |
| **Total** | | **7-12h** | ‚è≥ Pendente |

---

## ‚úÖ Checklist de Implementa√ß√£o

### Fase 1: An√°lise e Prepara√ß√£o
- [ ] Analisar estrutura do Open Interpreter
- [ ] Analisar interface do AutoGen
- [ ] Definir estrat√©gia de adapta√ß√£o

### Fase 2: Implementa√ß√£o do Agente
- [ ] Criar arquivo `open_interpreter_agent_integrated.py`
- [ ] Implementar classe `OpenInterpreterAgentIntegrated`
- [ ] Implementar m√©todo `_load_system_message()`
- [ ] Implementar m√©todo `_respond_with_autogen()`
- [ ] Implementar m√©todo `_process_response()`
- [ ] Implementar m√©todo `_execute_code()`
- [ ] Implementar m√©todo `process_message()`
- [ ] Criar fun√ß√£o helper `create_open_interpreter_agent_integrated()`

### Fase 3: Integra√ß√£o com AutoGen
- [ ] Atualizar `simple_commander.py`
- [ ] Adicionar configura√ß√£o `USE_INTEGRATED_AGENT`
- [ ] Testar integra√ß√£o com AutoGen

### Fase 4: Testes
- [ ] Testes unit√°rios
- [ ] Testes de integra√ß√£o
- [ ] Testes de performance

### Fase 5: Documenta√ß√£o
- [ ] Documentar agente
- [ ] Atualizar README
- [ ] Criar exemplos de uso

---

## üéØ Resultado Esperado

### Funcionalidades
- ‚úÖ Reutiliza 100% da l√≥gica do Open Interpreter
- ‚úÖ Usa model_client do AutoGen (mesmo modelo)
- ‚úÖ Executa c√≥digo Python, Shell, JavaScript, HTML
- ‚úÖ Active line tracking (AST transformation)
- ‚úÖ Output truncation
- ‚úÖ Error handling robusto
- ‚úÖ Zero overhead de comunica√ß√£o

### Performance
- ‚úÖ 0ms overhead (mesmo processo)
- ‚úÖ Mem√≥ria compartilhada
- ‚úÖ Integra√ß√£o nativa com AutoGen

### Manuten√ß√£o
- ‚úÖ C√≥digo limpo e documentado
- ‚úÖ Testes completos
- ‚úÖ F√°cil de manter

---

## üöÄ Pr√≥ximos Passos

1. **Come√ßar Fase 1:** An√°lise e Prepara√ß√£o
2. **Implementar Fase 2:** Criar agente integrado
3. **Integrar Fase 3:** Conectar com AutoGen
4. **Testar Fase 4:** Garantir funcionalidades
5. **Documentar Fase 5:** Criar documenta√ß√£o

---

## üìù Notas Importantes

### Vantagens
- ‚úÖ Reutiliza 100% da l√≥gica do Open Interpreter
- ‚úÖ Zero overhead de comunica√ß√£o
- ‚úÖ Integra√ß√£o nativa com AutoGen
- ‚úÖ Funcionalidades completas

### Desvantagens
- ‚ö†Ô∏è Mais c√≥digo (~300-400 linhas)
- ‚ö†Ô∏è Menos isolamento (mesmo processo)
- ‚ö†Ô∏è Manuten√ß√£o m√©dia (adaptar m√©todo)

### Recomenda√ß√£o
- ‚úÖ **TOOL √© mais eficiente para projeto est√°tico** (c√≥digo m√≠nimo, manuten√ß√£o baixa)
- ‚ö†Ô∏è **Agente integrado** s√≥ se precisar performance m√°xima (0ms overhead)

---

**Status: Plano completo criado. Pronto para implementa√ß√£o!** ‚úÖ

