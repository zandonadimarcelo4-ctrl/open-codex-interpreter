"""
üöÄ Super Agent - Vers√£o 100% Python (SIMPLIFICADA para Iniciantes)

Este arquivo cont√©m TUDO que voc√™ precisa para usar o Super Agent:
- ‚úÖ AutoGen (comanda tudo)
- ‚úÖ Open Interpreter (execu√ß√£o de c√≥digo)
- ‚úÖ Selenium (navega√ß√£o web)
- ‚úÖ PyAutoGUI/UFO (automa√ß√£o GUI)
- ‚úÖ After Effects MCP Vision (edi√ß√£o de v√≠deo) - OPCIONAL

COMO USAR:
1. Instale as depend√™ncias: pip install -r requirements.txt
2. Execute: python app_simples.py
3. Acesse: http://localhost:7860

TUDO est√° aqui, comentado em portugu√™s, f√°cil de entender! üéâ
"""

# ============================================================================
# IMPORTA√á√ïES (O que cada biblioteca faz)
# ============================================================================

import os
import logging
import asyncio
from pathlib import Path
from typing import Optional, Dict, Any, List

# Configurar logging (mensagens de debug)
# Isso mostra mensagens no terminal quando o programa roda
logging.basicConfig(
    level=logging.INFO,  # N√≠vel: INFO (mostra informa√ß√µes importantes)
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ----------------------------------------------------------------------------
# GRADIO (Interface Web Simples)
# ----------------------------------------------------------------------------
# Gradio cria uma interface web bonita automaticamente
# Voc√™ n√£o precisa saber HTML/CSS/JavaScript - s√≥ Python!
try:
    import gradio as gr
    GRADIO_AVAILABLE = True
except ImportError:
    GRADIO_AVAILABLE = False
    logger.warning("‚ö†Ô∏è Gradio n√£o est√° instalado. Instale com: pip install gradio")

# ----------------------------------------------------------------------------
# AUTOGEN (Comandante Inteligente)
# ----------------------------------------------------------------------------
# AutoGen √© o "chefe" que decide qual ferramenta usar
# Ele comanda TUDO: Open Interpreter, Selenium, PyAutoGUI, etc.
try:
    from .core.simple_commander import create_simple_commander
    from autogen_agentchat.teams import RoundRobinGroupChat
    AUTOGEN_AVAILABLE = True
    logger.info("‚úÖ AutoGen dispon√≠vel")
except ImportError as e:
    AUTOGEN_AVAILABLE = False
    logger.error(f"‚ùå AutoGen n√£o dispon√≠vel: {e}")
    logger.error("   Instale com: pip install autogen-agentchat autogen-ext[openai] autogen-ext[ollama]")

# ----------------------------------------------------------------------------
# CLASSIFICADOR DE INTEN√á√ÉO (Opcional)
# ----------------------------------------------------------------------------
# Detecta se a mensagem √© uma conversa ou uma a√ß√£o
# Exemplo: "Oi!" = conversa, "Executa c√≥digo" = a√ß√£o
try:
    from interpreter.intent_classifier import classify_intent
    INTENT_CLASSIFIER_AVAILABLE = True
    logger.info("‚úÖ Classificador de inten√ß√£o dispon√≠vel")
except ImportError:
    INTENT_CLASSIFIER_AVAILABLE = False
    logger.warning("‚ö†Ô∏è Classificador de inten√ß√£o n√£o dispon√≠vel (opcional)")

# ----------------------------------------------------------------------------
# AFTER EFFECTS MCP VISION (Opcional)
# ----------------------------------------------------------------------------
# Permite controlar Adobe After Effects via MCP (Model Context Protocol)
# Voc√™ pode criar composi√ß√µes, adicionar camadas, renderizar v√≠deos, etc.
try:
    from anima.agents.editor_agent_ae import AEMCPClient
    AFTER_EFFECTS_MCP_AVAILABLE = True
    logger.info("‚úÖ After Effects MCP dispon√≠vel")
except ImportError:
    AFTER_EFFECTS_MCP_AVAILABLE = False
    logger.warning("‚ö†Ô∏è After Effects MCP n√£o dispon√≠vel (opcional)")

# ============================================================================
# CONFIGURA√á√ÉO (Vari√°veis de Ambiente)
# ============================================================================

# Ollama √© o servidor que roda os modelos de IA localmente
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")

# Modelo padr√£o para conversas e racioc√≠nio
DEFAULT_MODEL = os.getenv("DEFAULT_MODEL", "qwen2.5:7b")

# Modelo para execu√ß√£o de c√≥digo (mais r√°pido, especializado em c√≥digo)
EXECUTOR_MODEL = os.getenv("EXECUTOR_MODEL", "qwen2.5-coder:7b")

# Workspace √© onde os arquivos s√£o criados/editados
WORKSPACE_PATH = os.getenv("WORKSPACE_PATH", str(Path.cwd() / "workspace"))

# Criar workspace se n√£o existir
workspace = Path(WORKSPACE_PATH)
workspace.mkdir(parents=True, exist_ok=True)
logger.info(f"üìÅ Workspace: {workspace}")

# ============================================================================
# CLASSE PRINCIPAL (SuperAgentApp)
# ============================================================================

class SuperAgentApp:
    """
    Aplica√ß√£o Super Agent - Vers√£o Simplificada para Iniciantes
    
    Esta classe faz TUDO:
    1. Inicializa o AutoGen Commander (chefe inteligente)
    2. Detecta a inten√ß√£o da mensagem (conversa ou a√ß√£o)
    3. Processa a mensagem (usando AutoGen ou Ollama)
    4. Cria a interface web (Gradio)
    5. Executa a aplica√ß√£o
    """
    
    def __init__(self):
        """
        Inicializar aplica√ß√£o
        
        O que acontece aqui:
        1. Cria o AutoGen Commander (se dispon√≠vel)
        2. Cria o team (grupo de agentes)
        3. Inicializa o hist√≥rico de conversas
        """
        # Vari√°veis da classe
        self.commander = None  # Comandante AutoGen (chefe inteligente)
        self.team = None       # Team de agentes (grupo de trabalho)
        self.history = []      # Hist√≥rico de conversas
        
        # Inicializar AutoGen Commander
        if AUTOGEN_AVAILABLE:
            try:
                logger.info("üöÄ Inicializando AutoGen Commander...")
                
                # Criar comandante AutoGen
                # Este √© o "chefe" que comanda tudo:
                # - Open Interpreter (execu√ß√£o de c√≥digo)
                # - Selenium (navega√ß√£o web)
                # - PyAutoGUI/UFO (automa√ß√£o GUI)
                # - After Effects MCP (edi√ß√£o de v√≠deo) - opcional
                self.commander = create_simple_commander(
                    model=DEFAULT_MODEL,                    # Modelo para racioc√≠nio
                    api_base=OLLAMA_BASE_URL,               # URL do Ollama
                    use_autonomous_agent=True,              # Open Interpreter integrado diretamente
                    workdir=str(workspace),                 # Diret√≥rio de trabalho
                    executor_model=EXECUTOR_MODEL,          # Modelo para execu√ß√£o de c√≥digo
                )
                
                # Criar team com comandante
                # RoundRobinGroupChat = cada agente fala na vez (rod√≠zio)
                self.team = RoundRobinGroupChat(agents=[self.commander])
                
                logger.info("‚úÖ AutoGen Commander inicializado com sucesso")
            except Exception as e:
                logger.error(f"‚ùå Erro ao inicializar AutoGen Commander: {e}")
                self.commander = None
                self.team = None
        else:
            logger.error("‚ùå AutoGen n√£o est√° dispon√≠vel. Instale com: pip install autogen-agentchat autogen-ext[openai] autogen-ext[ollama]")
    
    def detect_intent_simple(self, message: str) -> Dict[str, Any]:
        """
        Detectar inten√ß√£o da mensagem (conversa ou a√ß√£o)
        
        Esta fun√ß√£o decide se a mensagem √©:
        - CONVERSA: "Oi!", "Como voc√™ est√°?", "O que √© Python?"
        - A√á√ÉO: "Executa c√≥digo", "Abre o Google", "Tira screenshot"
        
        Args:
            message: Mensagem do usu√°rio
            
        Returns:
            Dicion√°rio com tipo de inten√ß√£o e confian√ßa
            Exemplo: {"type": "action", "confidence": 0.8, "reason": "Palavra-chave detectada: executa"}
        """
        # Converter mensagem para min√∫sculas (facilita compara√ß√£o)
        message_lower = message.lower().strip()
        
        # Palavras-chave de A√á√ÉO (fazer algo)
        # Se a mensagem cont√©m essas palavras, √© uma a√ß√£o
        action_keywords = [
            "executa", "cria", "edita", "abre", "pesquisa", "navega",
            "clica", "digita", "screenshot", "tira foto", "busca",
            "instala", "desinstala", "executa c√≥digo", "roda c√≥digo",
            "renderiza", "cria v√≠deo", "adiciona camada",  # After Effects
        ]
        
        # Palavras-chave de CONVERSA (s√≥ conversar)
        # Se a mensagem cont√©m essas palavras, √© uma conversa
        conversation_keywords = [
            "oi", "ol√°", "tudo bem", "como voc√™ est√°", "qual √©",
            "o que √©", "explique", "me diga", "me fale", "obrigado"
        ]
        
        # Verificar palavras-chave de A√á√ÉO
        # Se encontrar uma palavra-chave de a√ß√£o, retorna "action"
        for keyword in action_keywords:
            if message_lower.startswith(keyword) or keyword in message_lower:
                return {
                    "type": "action",
                    "confidence": 0.8,
                    "reason": f"Palavra-chave detectada: {keyword}"
                }
        
        # Verificar palavras-chave de CONVERSA
        # Se encontrar uma palavra-chave de conversa, retorna "conversation"
        for keyword in conversation_keywords:
            if message_lower.startswith(keyword) or keyword in message_lower:
                return {
                    "type": "conversation",
                    "confidence": 0.8,
                    "reason": f"Palavra-chave detectada: {keyword}"
                }
        
        # Se n√£o encontrou palavra-chave, tentar classificador (se dispon√≠vel)
        # O classificador usa IA para detectar a inten√ß√£o (mais preciso)
        if INTENT_CLASSIFIER_AVAILABLE:
            try:
                intent = classify_intent(message)
                return intent
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro ao usar classificador: {e}")
        
        # Padr√£o: assumir que √© conversa
        # Se n√£o conseguiu detectar, assume que √© uma conversa
        return {
            "type": "conversation",
            "confidence": 0.5,
            "reason": "Padr√£o: assumido como conversa"
        }
    
    async def process_message(self, message: str, history: list) -> tuple:
        """
        Processar mensagem do usu√°rio
        
        Esta fun√ß√£o faz o seguinte:
        1. Detecta a inten√ß√£o (conversa ou a√ß√£o)
        2. Se for A√á√ÉO ‚Üí usa AutoGen Commander (executa tarefas)
        3. Se for CONVERSA ‚Üí usa Ollama diretamente (mais r√°pido)
        4. Retorna a resposta
        
        Args:
            message: Mensagem do usu√°rio
            history: Hist√≥rico de conversas (formato Gradio)
                    Exemplo: [["Oi!", "Ol√°! Como posso ajudar?"], ["Executa: print('Hello')", "Hello"]]
        
        Returns:
            tuple: (nova_history, resposta)
                   nova_history = hist√≥rico atualizado
                   resposta = "" (vazio, porque a resposta j√° est√° no hist√≥rico)
        """
        # Verificar se a mensagem n√£o est√° vazia
        if not message or not message.strip():
            return history, "Por favor, digite uma mensagem."
        
        logger.info(f"üì® Mensagem recebida: {message[:50]}...")
        
        # Adicionar mensagem do usu√°rio ao hist√≥rico
        # Formato: [mensagem_usuario, resposta_assistente]
        # resposta_assistente = None inicialmente (ser√° preenchido depois)
        history = history or []
        history.append([message, None])
        
        try:
            # 1. DETECTAR INTEN√á√ÉO
            # Decide se √© conversa ou a√ß√£o
            intent = self.detect_intent_simple(message)
            logger.info(f"üéØ Inten√ß√£o detectada: {intent['type']} (confian√ßa: {intent['confidence']:.2f})")
            
            # 2. PROCESSAR MENSAGEM BASEADO NA INTEN√á√ÉO
            if intent["type"] == "action" and self.team:
                # A√á√ÉO: usar AutoGen Commander
                # AutoGen comanda TUDO: Open Interpreter, Selenium, PyAutoGUI, etc.
                logger.info("üöÄ Processando como a√ß√£o (AutoGen Commander)...")
                
                try:
                    # Executar tarefa usando AutoGen
                    # O AutoGen decide qual ferramenta usar automaticamente
                    result = await self.team.run(task=message)
                    
                    # Extrair resposta do resultado
                    if result and len(result.messages) > 0:
                        # Pegar a √∫ltima mensagem (resposta do agente)
                        last_message = result.messages[-1]
                        # Extrair conte√∫do da mensagem
                        response = last_message.content if hasattr(last_message, 'content') else str(last_message)
                    else:
                        # Se n√£o houve mensagens, assume sucesso
                        response = "‚úÖ Tarefa executada com sucesso!"
                    
                    logger.info(f"‚úÖ Resposta gerada: {response[:50]}...")
                    
                except Exception as e:
                    # Se der erro, retorna mensagem de erro
                    logger.error(f"‚ùå Erro ao executar tarefa: {e}")
                    response = f"‚ùå Erro ao executar tarefa: {str(e)}"
            
            else:
                # CONVERSA: usar Ollama diretamente (mais r√°pido)
                # Para conversas simples, n√£o precisa do AutoGen
                logger.info("üí¨ Processando como conversa (Ollama direto)...")
                
                try:
                    import requests
                    
                    # Chamar Ollama diretamente
                    # Ollama √© o servidor que roda os modelos de IA
                    response_ollama = requests.post(
                        f"{OLLAMA_BASE_URL}/api/generate",
                        json={
                            "model": DEFAULT_MODEL,  # Modelo a usar
                            "prompt": message,        # Mensagem do usu√°rio
                            "stream": False,          # N√£o usar streaming (mais simples)
                        },
                        timeout=60  # Timeout de 60 segundos
                    )
                    
                    # Verificar se a resposta foi bem-sucedida
                    if response_ollama.status_code == 200:
                        # Extrair resposta do JSON
                        data = response_ollama.json()
                        response = data.get("response", "Desculpe, n√£o consegui gerar uma resposta.")
                    else:
                        # Se der erro, retorna c√≥digo de erro
                        response = f"‚ùå Erro ao chamar Ollama: {response_ollama.status_code}"
                    
                    logger.info(f"‚úÖ Resposta gerada: {response[:50]}...")
                    
                except Exception as e:
                    # Se der erro, retorna mensagem de erro
                    logger.error(f"‚ùå Erro ao processar conversa: {e}")
                    response = f"‚ùå Erro ao processar conversa: {str(e)}"
            
            # 3. ATUALIZAR HIST√ìRICO
            # Adicionar resposta ao hist√≥rico
            history[-1][1] = response
            
            # Retornar hist√≥rico atualizado e resposta vazia
            # (resposta vazia porque a resposta j√° est√° no hist√≥rico)
            return history, ""
            
        except Exception as e:
            # Se der erro em qualquer lugar, retorna mensagem de erro
            logger.error(f"‚ùå Erro ao processar mensagem: {e}")
            error_response = f"‚ùå Erro ao processar mensagem: {str(e)}"
            history[-1][1] = error_response
            return history, ""
    
    def create_interface(self):
        """
        Criar interface Gradio (Interface Web)
        
        Gradio cria uma interface web bonita automaticamente.
        Voc√™ n√£o precisa saber HTML/CSS/JavaScript - s√≥ Python!
        
        Esta fun√ß√£o cria:
        - T√≠tulo e descri√ß√£o
        - Chat (√°rea de mensagens)
        - Campo de entrada (para digitar mensagens)
        - Bot√µes (Enviar, Limpar)
        - Status (informa√ß√µes sobre o sistema)
        
        Returns:
            Interface Gradio configurada
        """
        if not GRADIO_AVAILABLE:
            raise ImportError("Gradio n√£o est√° instalado. Instale com: pip install gradio")
        
        # Criar interface de chat
        # gr.Blocks = container principal (caixa que cont√©m tudo)
        # theme=gr.themes.Soft() = tema suave (bonito)
        with gr.Blocks(
            title="ü§ñ Super Agent - Chat Inteligente",
            theme=gr.themes.Soft(),
        ) as interface:
            
            # T√çTULO E DESCRI√á√ÉO
            # gr.Markdown = texto formatado (como markdown)
            gr.Markdown("""
            # ü§ñ Super Agent - Chat Inteligente
            
            **Vers√£o 100% Python** - Simples para Iniciantes
            
            Este assistente pode:
            - üí¨ Conversar com voc√™
            - üöÄ Executar tarefas (c√≥digo, navega√ß√£o web, automa√ß√£o GUI)
            - üîß Usar AutoGen, Open Interpreter, Selenium, PyAutoGUI
            - üé¨ Editar v√≠deos (After Effects MCP) - Opcional
            """)
            
            # CHAT (√Årea de Mensagens)
            # gr.Chatbot = √°rea onde as mensagens aparecem
            chatbot = gr.Chatbot(
                label="Chat",        # T√≠tulo do chat
                height=500,          # Altura em pixels
                show_label=True,     # Mostrar t√≠tulo
            )
            
            # CAMPO DE ENTRADA (Para Digitar Mensagens)
            # gr.Textbox = campo de texto (para digitar)
            msg = gr.Textbox(
                label="Digite sua mensagem",                    # T√≠tulo do campo
                placeholder="Ex: Oi! ou Executa: print('Hello World')",  # Texto de exemplo
                lines=2,                                         # N√∫mero de linhas
            )
            
            # BOT√ïES
            # gr.Row = linha (organiza bot√µes lado a lado)
            with gr.Row():
                # Bot√£o Enviar
                submit_btn = gr.Button("Enviar", variant="primary")  # Bot√£o principal (azul)
                # Bot√£o Limpar
                clear_btn = gr.Button("Limpar")                      # Bot√£o secund√°rio (cinza)
            
            # STATUS (Informa√ß√µes sobre o Sistema)
            # Mostra o status do sistema (AutoGen dispon√≠vel, workspace, etc.)
            status_text = f"""
            **Status:**
            - ‚úÖ Interface carregada
            - {'‚úÖ' if AUTOGEN_AVAILABLE else '‚ùå'} AutoGen: {'Dispon√≠vel' if AUTOGEN_AVAILABLE else 'N√£o dispon√≠vel'}
            - {'‚úÖ' if AFTER_EFFECTS_MCP_AVAILABLE else '‚ö†Ô∏è'} After Effects MCP: {'Dispon√≠vel' if AFTER_EFFECTS_MCP_AVAILABLE else 'N√£o dispon√≠vel (opcional)'}
            - üìÅ Workspace: {workspace}
            """
            status = gr.Markdown(status_text)
            
            # FUN√á√ÉO PARA ENVIAR MENSAGEM
            # Esta fun√ß√£o √© chamada quando o usu√°rio clica em "Enviar" ou pressiona Enter
            def user_message(message, history):
                """
                Processar mensagem do usu√°rio
                
                Esta fun√ß√£o:
                1. Recebe a mensagem e o hist√≥rico
                2. Chama process_message (que √© async)
                3. Retorna o hist√≥rico atualizado
                
                Args:
                    message: Mensagem do usu√°rio
                    history: Hist√≥rico de conversas
                
                Returns:
                    tuple: (nova_history, "")
                           nova_history = hist√≥rico atualizado
                           "" = resposta vazia (porque a resposta j√° est√° no hist√≥rico)
                """
                # Converter para formato async
                # Gradio n√£o suporta async diretamente, ent√£o criamos um loop
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    # Executar process_message
                    new_history, _ = loop.run_until_complete(
                        self.process_message(message, history)
                    )
                    # Retornar hist√≥rico atualizado e resposta vazia
                    return new_history, ""
                finally:
                    # Fechar loop (importante para n√£o vazar recursos)
                    loop.close()
            
            # CONECTAR EVENTOS
            # Conectar bot√µes e campos √† fun√ß√£o user_message
            
            # Quando o usu√°rio pressiona Enter no campo de texto
            msg.submit(user_message, [msg, chatbot], [chatbot, msg])
            # Quando o usu√°rio clica no bot√£o "Enviar"
            submit_btn.click(user_message, [msg, chatbot], [chatbot, msg])
            # Quando o usu√°rio clica no bot√£o "Limpar"
            clear_btn.click(lambda: ([], ""), None, [chatbot, msg])
        
        # Retornar interface criada
        return interface
    
    def run(self, server_name: str = "0.0.0.0", server_port: int = 7860, share: bool = False):
        """
        Executar aplica√ß√£o
        
        Esta fun√ß√£o:
        1. Cria a interface Gradio
        2. Inicia o servidor web
        3. Abre no navegador (http://localhost:7860)
        
        Args:
            server_name: Endere√ßo do servidor (padr√£o: 0.0.0.0 - acess√≠vel de qualquer lugar)
            server_port: Porta do servidor (padr√£o: 7860)
            share: Se True, cria link p√∫blico (padr√£o: False)
        """
        if not GRADIO_AVAILABLE:
            logger.error("‚ùå Gradio n√£o est√° instalado. Instale com: pip install gradio")
            return
        
        logger.info("üöÄ Iniciando Super Agent...")
        logger.info(f"üì° Servidor: {server_name}:{server_port}")
        logger.info(f"üåê Acesse: http://localhost:{server_port}")
        
        # Criar interface
        interface = self.create_interface()
        
        # Executar interface
        # launch() inicia o servidor web e abre no navegador
        interface.launch(
            server_name=server_name,  # Endere√ßo do servidor
            server_port=server_port,  # Porta do servidor
            share=share,              # Se True, cria link p√∫blico
        )


# ============================================================================
# FUN√á√ÉO PRINCIPAL (main)
# ============================================================================

def main():
    """
    Fun√ß√£o principal
    
    Esta fun√ß√£o:
    1. Cria a aplica√ß√£o SuperAgentApp
    2. Executa a aplica√ß√£o
    
    √â a fun√ß√£o que √© chamada quando voc√™ executa: python app_simples.py
    """
    # Criar aplica√ß√£o
    app = SuperAgentApp()
    
    # Executar aplica√ß√£o
    app.run(
        server_name="0.0.0.0",  # Acess√≠vel de qualquer lugar (0.0.0.0 = todas as interfaces)
        server_port=7860,       # Porta 7860 (padr√£o do Gradio)
        share=False,            # Se True, cria link p√∫blico (√∫til para compartilhar)
    )


# ============================================================================
# PONTO DE ENTRADA (Quando o arquivo √© executado)
# ============================================================================

if __name__ == "__main__":
    # Quando voc√™ executa: python app_simples.py
    # Esta linha chama a fun√ß√£o main()
    main()
